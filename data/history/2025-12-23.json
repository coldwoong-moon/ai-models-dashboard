{
  "last_updated": "2025-12-23T00:34:58.372102",
  "providers": {
    "deepseek": {
      "name": "Deepseek",
      "website": "",
      "api_endpoint": "",
      "last_updated": "2025-12-23T00:34:47.448478",
      "model_count": 3
    },
    "anthropic": {
      "name": "Anthropic",
      "website": "https://anthropic.com",
      "api_endpoint": "https://api.anthropic.com",
      "last_updated": "2025-12-23T00:34:35.560002",
      "model_count": 5
    },
    "openai": {
      "name": "OpenAI",
      "website": "https://openai.com",
      "api_endpoint": "https://api.openai.com/v1",
      "last_updated": "2025-12-23T00:34:27.459901",
      "model_count": 6
    },
    "google": {
      "name": "Google AI",
      "website": "https://ai.google.dev",
      "api_endpoint": "https://generativelanguage.googleapis.com",
      "last_updated": "2025-12-23T00:34:41.840743",
      "model_count": 44
    },
    "mistral": {
      "name": "Mistral AI",
      "website": "https://mistral.ai",
      "api_endpoint": "https://api.mistral.ai",
      "last_updated": "2025-12-23T00:34:57.996957",
      "model_count": 6
    },
    "cohere": {
      "name": "Cohere",
      "website": "https://cohere.com",
      "api_endpoint": "https://api.cohere.ai",
      "last_updated": "2025-12-23T00:34:58.136046",
      "model_count": 11
    },
    "xai": {
      "name": "Xai",
      "website": "",
      "api_endpoint": "",
      "last_updated": "2025-12-23T00:34:51.893250",
      "model_count": 3
    },
    "meta": {
      "name": "Meta",
      "website": "https://meta.com",
      "api_endpoint": "https://api.meta.com",
      "last_updated": "2025-07-17T16:57:28.119320",
      "model_count": 2
    },
    "huggingface": {
      "name": "HuggingFace",
      "website": "https://huggingface.co",
      "api_endpoint": "https://api-inference.huggingface.co",
      "last_updated": "2025-12-23T00:34:58.245892",
      "model_count": 11
    }
  },
  "models": [
    {
      "id": "deepseek-chat",
      "name": "DeepSeek-V3",
      "provider": "deepseek",
      "description": "DeepSeek-V3: 671B parameter model excelling at reasoning, coding, and math",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 64000,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "math",
        "reasoning",
        "long-context",
        "multilingual",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:47.448380",
      "unique_id": "deepseek/deepseek-chat"
    },
    {
      "id": "deepseek-reasoner",
      "name": "DeepSeek-R1",
      "provider": "deepseek",
      "description": "Advanced reasoning model with transparent thinking process",
      "pricing": {
        "input": 0.55,
        "output": 2.19,
        "unit": "1M tokens"
      },
      "context_window": 64000,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "reasoning",
        "thinking",
        "transparent-reasoning",
        "math",
        "complex-tasks"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:47.448391",
      "unique_id": "deepseek/deepseek-reasoner"
    },
    {
      "id": "deepseek-coder",
      "name": "DeepSeek-Coder-V2",
      "provider": "deepseek",
      "description": "Specialized model for code generation and analysis",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "coding",
        "code-generation",
        "code-analysis",
        "debugging",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:47.448396",
      "unique_id": "deepseek/deepseek-coder"
    },
    {
      "id": "claude-3-5-sonnet-20241022",
      "name": "Claude 3.5 Sonnet",
      "provider": "anthropic",
      "description": "Most intelligent model with advanced reasoning, coding, and vision capabilities",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "analysis",
        "creative-writing",
        "vision",
        "computer-use",
        "reasoning"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:35.559925",
      "unique_id": "anthropic/claude-3-5-sonnet-20241022"
    },
    {
      "id": "claude-3-5-haiku-20241022",
      "name": "Claude 3.5 Haiku",
      "provider": "anthropic",
      "description": "Fast and affordable model with vision capabilities for everyday tasks",
      "pricing": {
        "input": 0.8,
        "output": 4.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "fast",
        "vision",
        "cost-effective"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:35.559935",
      "unique_id": "anthropic/claude-3-5-haiku-20241022"
    },
    {
      "id": "claude-3-opus-20240229",
      "name": "Claude 3 Opus",
      "provider": "anthropic",
      "description": "Most powerful model for complex reasoning and research tasks",
      "pricing": {
        "input": 15.0,
        "output": 75.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "analysis",
        "research",
        "complex-reasoning",
        "vision",
        "creative-writing"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:35.559938",
      "unique_id": "anthropic/claude-3-opus-20240229"
    },
    {
      "id": "claude-3-sonnet-20240229",
      "name": "Claude 3 Sonnet",
      "provider": "anthropic",
      "description": "Balanced model for general purpose tasks with good performance",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "analysis",
        "vision",
        "general-purpose"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:35.559941",
      "unique_id": "anthropic/claude-3-sonnet-20240229"
    },
    {
      "id": "claude-3-haiku-20240307",
      "name": "Claude 3 Haiku",
      "provider": "anthropic",
      "description": "Fastest and most compact model for simple tasks",
      "pricing": {
        "input": 0.25,
        "output": 1.25,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "fast",
        "lightweight",
        "vision",
        "simple-tasks"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:35.559944",
      "unique_id": "anthropic/claude-3-haiku-20240307"
    },
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "openai",
      "description": "Most capable multimodal model with vision and advanced reasoning",
      "pricing": {
        "input": 2.5,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 16384,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459803",
      "unique_id": "openai/gpt-4o"
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT-4o mini",
      "provider": "openai",
      "description": "Affordable multimodal model with vision capabilities",
      "pricing": {
        "input": 0.15,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 16384,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode",
        "fast",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459816",
      "unique_id": "openai/gpt-4o-mini"
    },
    {
      "id": "o1",
      "name": "o1",
      "provider": "openai",
      "description": "Advanced reasoning model for complex problem-solving",
      "pricing": {
        "input": 15.0,
        "output": 60.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 100000,
      "release_date": "",
      "status": "ga",
      "features": [
        "reasoning",
        "complex-tasks",
        "thinking",
        "math",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459821",
      "unique_id": "openai/o1"
    },
    {
      "id": "o1-mini",
      "name": "o1-mini",
      "provider": "openai",
      "description": "Fast reasoning model optimized for coding and STEM",
      "pricing": {
        "input": 3.0,
        "output": 12.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 65536,
      "release_date": "",
      "status": "ga",
      "features": [
        "reasoning",
        "coding",
        "fast",
        "thinking",
        "math",
        "stem"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459825",
      "unique_id": "openai/o1-mini"
    },
    {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "provider": "openai",
      "description": "Previous generation high-intelligence model with vision",
      "pricing": {
        "input": 10.0,
        "output": 30.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459828",
      "unique_id": "openai/gpt-4-turbo"
    },
    {
      "id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "provider": "openai",
      "description": "Fast and cost-effective model for simple tasks",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "unit": "1M tokens"
      },
      "context_window": 16385,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "function-calling",
        "fast",
        "cost-effective"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:27.459833",
      "unique_id": "openai/gpt-3.5-turbo"
    },
    {
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "provider": "mistral",
      "description": "Top-tier reasoning model for complex tasks",
      "pricing": {
        "input": 3.0,
        "output": 9.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "complex-tasks",
        "multilingual",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996878",
      "unique_id": "mistral/mistral-large-latest"
    },
    {
      "id": "mistral-small-latest",
      "name": "Mistral Small",
      "provider": "mistral",
      "description": "Cost-efficient model for simple tasks",
      "pricing": {
        "input": 0.2,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "fast",
        "cost-efficient",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996888",
      "unique_id": "mistral/mistral-small-latest"
    },
    {
      "id": "open-mixtral-8x7b",
      "name": "Mixtral 8x7B",
      "provider": "mistral",
      "description": "Mixture of experts model with 8x7B parameters",
      "pricing": {
        "input": 0.5,
        "output": 0.5,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "mixture-of-experts",
        "efficient",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996891",
      "unique_id": "mistral/open-mixtral-8x7b"
    },
    {
      "id": "open-mixtral-8x22b",
      "name": "Mixtral 8x22B",
      "provider": "mistral",
      "description": "Large mixture of experts model with 8x22B parameters",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "context_window": 65536,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "mixture-of-experts",
        "powerful",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996894",
      "unique_id": "mistral/open-mixtral-8x22b"
    },
    {
      "id": "pixtral-12b",
      "name": "Pixtral 12B",
      "provider": "mistral",
      "description": "Multimodal model for text and image understanding",
      "pricing": {
        "input": 0.15,
        "output": 0.15,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "multimodal",
        "image-understanding"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996896",
      "unique_id": "mistral/pixtral-12b"
    },
    {
      "id": "codestral-latest",
      "name": "Codestral",
      "provider": "mistral",
      "description": "Specialized model for code generation",
      "pricing": {
        "input": 0.2,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "coding",
        "code-generation",
        "fill-in-the-middle",
        "multilingual-code"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:57.996899",
      "unique_id": "mistral/codestral-latest"
    },
    {
      "id": "command-r-plus",
      "name": "Command R+",
      "provider": "cohere",
      "description": "Advanced conversational AI optimized for complex reasoning and RAG",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-04-04",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "rag",
        "function-calling",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Complex reasoning tasks",
        "RAG applications",
        "Enterprise chatbots",
        "Document analysis",
        "Knowledge base queries",
        "Multi-step workflows"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2025-12-23T00:34:58.135966",
      "unique_id": "cohere/command-r-plus"
    },
    {
      "id": "command-r",
      "name": "Command R",
      "provider": "cohere",
      "description": "Balanced model for retrieval-augmented generation and conversation",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-03-11",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "rag",
        "function-calling",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Retrieval-augmented generation",
        "Information synthesis",
        "Customer support",
        "Content generation",
        "Question answering"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2025-12-23T00:34:58.135977",
      "unique_id": "cohere/command-r"
    },
    {
      "id": "command",
      "name": "Command",
      "provider": "cohere",
      "description": "General-purpose conversational AI model",
      "pricing": {
        "input": 1.0,
        "output": 2.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 4096,
      "release_date": "2023-06-01",
      "status": "ga",
      "features": [
        "chat",
        "reasoning"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "General conversations",
        "Content creation",
        "Text summarization",
        "Simple Q&A"
      ],
      "training_cutoff": "2023-03",
      "last_updated": "2025-12-23T00:34:58.135980",
      "unique_id": "cohere/command"
    },
    {
      "id": "command-light",
      "name": "Command Light",
      "provider": "cohere",
      "description": "Faster, lighter version for simple tasks",
      "pricing": {
        "input": 0.3,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 4096,
      "release_date": "2023-06-01",
      "status": "ga",
      "features": [
        "chat",
        "fast-inference"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "High-throughput applications",
        "Real-time chat",
        "Simple text generation",
        "Cost-sensitive deployments"
      ],
      "training_cutoff": "2023-03",
      "last_updated": "2025-12-23T00:34:58.135982",
      "unique_id": "cohere/command-light"
    },
    {
      "id": "command-nightly",
      "name": "Command Nightly",
      "provider": "cohere",
      "description": "Experimental model with latest features",
      "pricing": {
        "input": 15.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-01-01",
      "status": "experimental",
      "features": [
        "chat",
        "reasoning",
        "experimental"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Experimental features testing",
        "Cutting-edge capabilities",
        "Research applications"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2025-12-23T00:34:58.135984",
      "unique_id": "cohere/command-nightly"
    },
    {
      "id": "embed-english-v3.0",
      "name": "Embed English v3.0",
      "provider": "cohere",
      "description": "State-of-the-art English text embeddings",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "semantic-search",
        "clustering"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Semantic search",
        "Text similarity",
        "Document clustering",
        "Recommendation systems",
        "Content classification"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.135987",
      "unique_id": "cohere/embed-english-v3.0"
    },
    {
      "id": "embed-multilingual-v3.0",
      "name": "Embed Multilingual v3.0",
      "provider": "cohere",
      "description": "Multilingual text embeddings supporting 100+ languages",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "multilingual",
        "semantic-search"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Cross-lingual search",
        "Multilingual clustering",
        "Global content analysis",
        "International applications"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.135989",
      "unique_id": "cohere/embed-multilingual-v3.0"
    },
    {
      "id": "embed-english-light-v3.0",
      "name": "Embed English Light v3.0",
      "provider": "cohere",
      "description": "Lightweight English embeddings for high-throughput applications",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "fast-inference",
        "lightweight"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "High-volume embeddings",
        "Real-time similarity",
        "Edge deployments"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.135996",
      "unique_id": "cohere/embed-english-light-v3.0"
    },
    {
      "id": "embed-multilingual-light-v3.0",
      "name": "Embed Multilingual Light v3.0",
      "provider": "cohere",
      "description": "Lightweight multilingual embeddings",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "multilingual",
        "lightweight"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Lightweight multilingual search",
        "Fast cross-lingual matching"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.136000",
      "unique_id": "cohere/embed-multilingual-light-v3.0"
    },
    {
      "id": "rerank-english-v3.0",
      "name": "Rerank English v3.0",
      "provider": "cohere",
      "description": "Advanced reranking model for search relevance",
      "pricing": {
        "input": 2.0,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 1,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "reranking",
        "search-optimization",
        "relevance-scoring"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Search result optimization",
        "Relevance scoring",
        "Information retrieval",
        "Query optimization"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.136002",
      "unique_id": "cohere/rerank-english-v3.0"
    },
    {
      "id": "rerank-multilingual-v3.0",
      "name": "Rerank Multilingual v3.0",
      "provider": "cohere",
      "description": "Multilingual reranking for global search applications",
      "pricing": {
        "input": 2.0,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 1,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "reranking",
        "multilingual",
        "search-optimization"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Global search systems",
        "Multilingual relevance",
        "Cross-language retrieval"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2025-12-23T00:34:58.136004",
      "unique_id": "cohere/rerank-multilingual-v3.0"
    },
    {
      "id": "grok-2",
      "name": "Grok-2",
      "provider": "xai",
      "description": "Advanced reasoning model with real-time knowledge from X platform",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 131072,
      "max_output": 4096,
      "release_date": "2024",
      "status": "ga",
      "features": [
        "chat",
        "real-time",
        "x-integration",
        "reasoning",
        "coding",
        "multilingual",
        "current-events"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:51.893173",
      "unique_id": "xai/grok-2"
    },
    {
      "id": "grok-2-vision",
      "name": "Grok-2 Vision",
      "provider": "xai",
      "description": "Multimodal model with vision capabilities and real-time knowledge",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 131072,
      "max_output": 4096,
      "release_date": "2024",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "real-time",
        "x-integration",
        "multimodal",
        "reasoning",
        "image-analysis"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:51.893183",
      "unique_id": "xai/grok-2-vision"
    },
    {
      "id": "grok-beta",
      "name": "Grok-3 (Beta)",
      "provider": "xai",
      "description": "Next generation Grok model with enhanced capabilities",
      "pricing": {
        "input": 5.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 8192,
      "release_date": "2024",
      "status": "beta",
      "features": [
        "chat",
        "reasoning",
        "advanced-capabilities",
        "beta",
        "next-gen"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:51.893192",
      "unique_id": "xai/grok-beta"
    },
    {
      "id": "llama-4-scout",
      "name": "Llama 4 Scout",
      "provider": "meta",
      "description": "Fast and efficient Llama 4 model optimized for speed",
      "pricing": {
        "input": 0.8,
        "output": 2.4,
        "unit": "1M tokens"
      },
      "input_price": 0.8,
      "output_price": 2.4,
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2025-04-15",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "reasoning",
        "fast",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-07-17T16:57:28.119309",
      "notes": "Released April 2025 - Fastest Llama 4 variant",
      "source": "manual_curation",
      "unique_id": "meta/llama-4-scout"
    },
    {
      "id": "llama-4-maverick",
      "name": "Llama 4 Maverick",
      "provider": "meta",
      "description": "Powerful Llama 4 model with advanced reasoning capabilities",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "input_price": 2.0,
      "output_price": 6.0,
      "context_window": 256000,
      "max_output": 16384,
      "release_date": "2025-04-15",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "reasoning",
        "creative-writing",
        "analysis",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-07-17T16:57:28.119312",
      "notes": "Released April 2025 - Most capable Llama 4 variant",
      "source": "manual_curation",
      "unique_id": "meta/llama-4-maverick"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "name": "Meta Llama 3.1 405B Instruct",
      "provider": "huggingface",
      "description": "Meta의 최대 규모 오픈소스 LLM, 405B 파라미터",
      "pricing": {
        "input": 5.0,
        "output": 16.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245824",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "name": "Meta Llama 3.1 70B Instruct",
      "provider": "huggingface",
      "description": "고품질 오픈소스 LLM, 70B 파라미터",
      "pricing": {
        "input": 0.9,
        "output": 0.9,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245833",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "name": "Meta Llama 3.1 8B Instruct",
      "provider": "huggingface",
      "description": "효율적인 오픈소스 LLM, 8B 파라미터",
      "pricing": {
        "input": 0.2,
        "output": 0.2,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245836",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    {
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral 8x7B Instruct",
      "provider": "huggingface",
      "description": "Mistral의 MoE 아키텍처 모델",
      "pricing": {
        "input": 0.7,
        "output": 0.7,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "moe"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245838",
      "unique_id": "huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1"
    },
    {
      "id": "mistralai/Mistral-7B-Instruct-v0.3",
      "name": "Mistral 7B Instruct v0.3",
      "provider": "huggingface",
      "description": "Mistral의 효율적인 7B 모델",
      "pricing": {
        "input": 0.25,
        "output": 0.25,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245840",
      "unique_id": "huggingface/mistralai/Mistral-7B-Instruct-v0.3"
    },
    {
      "id": "google/gemma-2-27b-it",
      "name": "Google Gemma 2 27B IT",
      "provider": "huggingface",
      "description": "Google의 오픈 모델 Gemma 2세대",
      "pricing": {
        "input": 0.8,
        "output": 0.8,
        "unit": "1M tokens"
      },
      "context_window": 8192,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245842",
      "unique_id": "huggingface/google/gemma-2-27b-it"
    },
    {
      "id": "google/gemma-2-9b-it",
      "name": "Google Gemma 2 9B IT",
      "provider": "huggingface",
      "description": "Google의 경량 Gemma 모델",
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "unit": "1M tokens"
      },
      "context_window": 8192,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245844",
      "unique_id": "huggingface/google/gemma-2-9b-it"
    },
    {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "name": "Qwen 2.5 72B Instruct",
      "provider": "huggingface",
      "description": "Alibaba의 강력한 다국어 모델",
      "pricing": {
        "input": 0.9,
        "output": 0.9,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245849",
      "unique_id": "huggingface/Qwen/Qwen2.5-72B-Instruct"
    },
    {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "name": "Qwen 2.5 7B Instruct",
      "provider": "huggingface",
      "description": "Qwen 경량 모델",
      "pricing": {
        "input": 0.25,
        "output": 0.25,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245852",
      "unique_id": "huggingface/Qwen/Qwen2.5-7B-Instruct"
    },
    {
      "id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "name": "Llama 3.2 11B Vision Instruct",
      "provider": "huggingface",
      "description": "Meta의 비전 기능이 있는 Llama 모델",
      "pricing": {
        "input": 0.35,
        "output": 0.35,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "instruct",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245854",
      "unique_id": "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "id": "microsoft/Phi-3-medium-128k-instruct",
      "name": "Phi-3 Medium 128K Instruct",
      "provider": "huggingface",
      "description": "Microsoft의 효율적인 소형 모델",
      "pricing": {
        "input": 0.4,
        "output": 0.4,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "long-context"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-12-23T00:34:58.245856",
      "unique_id": "huggingface/microsoft/Phi-3-medium-128k-instruct"
    }
  ],
  "statistics": {
    "total_models": 47,
    "free_models": 45,
    "paid_models": 2,
    "providers": 8,
    "provider_breakdown": {
      "deepseek": 3,
      "anthropic": 5,
      "openai": 6,
      "mistral": 6,
      "cohere": 11,
      "xai": 3,
      "meta": 2,
      "huggingface": 11
    },
    "price_range": {
      "min": 0.1,
      "max": 15.0,
      "average": 2.26
    },
    "features": {
      "chat": 36,
      "coding": 14,
      "math": 4,
      "reasoning": 15,
      "long-context": 2,
      "multilingual": 18,
      "function-calling": 9,
      "thinking": 3,
      "transparent-reasoning": 1,
      "complex-tasks": 3,
      "code-generation": 2,
      "code-analysis": 1,
      "debugging": 1,
      "analysis": 4,
      "creative-writing": 3,
      "vision": 11,
      "computer-use": 1,
      "fast": 7,
      "cost-effective": 2,
      "research": 1,
      "complex-reasoning": 1,
      "general-purpose": 1,
      "lightweight": 3,
      "simple-tasks": 1,
      "json-mode": 3,
      "multimodal": 5,
      "stem": 1,
      "cost-efficient": 1,
      "mixture-of-experts": 2,
      "efficient": 1,
      "powerful": 1,
      "image-understanding": 1,
      "fill-in-the-middle": 1,
      "multilingual-code": 1,
      "rag": 2,
      "fast-inference": 2,
      "experimental": 1,
      "embeddings": 4,
      "semantic-search": 2,
      "clustering": 1,
      "reranking": 2,
      "search-optimization": 2,
      "relevance-scoring": 1,
      "real-time": 2,
      "x-integration": 2,
      "current-events": 1,
      "image-analysis": 1,
      "advanced-capabilities": 1,
      "beta": 1,
      "next-gen": 1,
      "instruct": 11,
      "moe": 1
    },
    "modalities": {
      "text": 47,
      "image": 11
    },
    "status": {
      "ga": 45,
      "experimental": 1,
      "beta": 1
    },
    "context_windows": {
      "min": 512,
      "max": 256000,
      "over_100k": 26,
      "over_1m": 0
    }
  },
  "metadata": {
    "version": "1.0",
    "data_sources": [
      {
        "provider": "deepseek",
        "file": "deepseek.json",
        "last_updated": "2025-12-23T00:34:47.448478"
      },
      {
        "provider": "anthropic",
        "file": "anthropic.json",
        "last_updated": "2025-12-23T00:34:35.560002"
      },
      {
        "provider": "openai",
        "file": "openai.json",
        "last_updated": "2025-12-23T00:34:27.459901"
      },
      {
        "provider": "google",
        "file": "google.json",
        "last_updated": "2025-12-23T00:34:41.840743"
      },
      {
        "provider": "mistral",
        "file": "mistral.json",
        "last_updated": "2025-12-23T00:34:57.996957"
      },
      {
        "provider": "cohere",
        "file": "cohere.json",
        "last_updated": "2025-12-23T00:34:58.136046"
      },
      {
        "provider": "xai",
        "file": "xai.json",
        "last_updated": "2025-12-23T00:34:51.893250"
      },
      {
        "provider": "meta",
        "file": "meta.json",
        "last_updated": "2025-07-17T16:57:28.119320"
      },
      {
        "provider": "huggingface",
        "file": "huggingface.json",
        "last_updated": "2025-12-23T00:34:58.245892"
      }
    ]
  },
  "categories": {
    "vision_models": [
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/gpt-4-turbo",
      "mistral/pixtral-12b",
      "xai/grok-2-vision",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    ],
    "coding_models": [
      "deepseek/deepseek-coder",
      "mistral/codestral-latest"
    ],
    "reasoning_models": [
      "deepseek/deepseek-chat",
      "deepseek/deepseek-reasoner",
      "anthropic/claude-3-5-sonnet-20241022",
      "openai/o1",
      "openai/o1-mini",
      "mistral/mistral-large-latest",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command",
      "cohere/command-nightly",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-beta",
      "meta/llama-4-scout",
      "meta/llama-4-maverick"
    ],
    "fast_models": [
      "openai/gpt-4o-mini",
      "openai/o1-mini",
      "mistral/mistral-small-latest",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    ],
    "large_context": [
      "deepseek/deepseek-coder",
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o1",
      "openai/o1-mini",
      "openai/gpt-4-turbo",
      "mistral/mistral-large-latest",
      "mistral/pixtral-12b",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command-nightly",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-beta",
      "meta/llama-4-scout",
      "meta/llama-4-maverick",
      "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct",
      "huggingface/microsoft/Phi-3-medium-128k-instruct"
    ],
    "multimodal": [
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/gpt-4-turbo",
      "mistral/pixtral-12b",
      "xai/grok-2-vision",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    ],
    "free_models": [
      "deepseek/deepseek-chat",
      "deepseek/deepseek-reasoner",
      "deepseek/deepseek-coder",
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o1",
      "openai/o1-mini",
      "openai/gpt-4-turbo",
      "openai/gpt-3.5-turbo",
      "mistral/mistral-large-latest",
      "mistral/mistral-small-latest",
      "mistral/open-mixtral-8x7b",
      "mistral/open-mixtral-8x22b",
      "mistral/pixtral-12b",
      "mistral/codestral-latest",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command",
      "cohere/command-light",
      "cohere/command-nightly",
      "cohere/embed-english-v3.0",
      "cohere/embed-multilingual-v3.0",
      "cohere/embed-english-light-v3.0",
      "cohere/embed-multilingual-light-v3.0",
      "cohere/rerank-english-v3.0",
      "cohere/rerank-multilingual-v3.0",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-beta",
      "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "huggingface/mistralai/Mistral-7B-Instruct-v0.3",
      "huggingface/google/gemma-2-27b-it",
      "huggingface/google/gemma-2-9b-it",
      "huggingface/Qwen/Qwen2.5-72B-Instruct",
      "huggingface/Qwen/Qwen2.5-7B-Instruct",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct",
      "huggingface/microsoft/Phi-3-medium-128k-instruct"
    ],
    "experimental": [
      "cohere/command-nightly",
      "xai/grok-beta"
    ],
    "deprecated": []
  }
}