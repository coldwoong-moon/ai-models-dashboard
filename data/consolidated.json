{
  "last_updated": "2026-02-11T23:38:29.396339",
  "providers": {
    "deepseek": {
      "name": "Deepseek",
      "website": "",
      "api_endpoint": "",
      "last_updated": "2026-02-11T23:38:28.668846",
      "model_count": 6
    },
    "anthropic": {
      "name": "Anthropic",
      "website": "https://anthropic.com",
      "api_endpoint": "https://api.anthropic.com",
      "last_updated": "2026-02-11T23:38:28.669388",
      "model_count": 8
    },
    "openai": {
      "name": "OpenAI",
      "website": "https://openai.com",
      "api_endpoint": "https://api.openai.com/v1",
      "last_updated": "2026-02-11T23:38:29.327704",
      "model_count": 6
    },
    "google": {
      "name": "Google AI",
      "website": "https://ai.google.dev",
      "api_endpoint": "https://generativelanguage.googleapis.com",
      "last_updated": "2026-02-11T23:38:28.668844",
      "model_count": 8
    },
    "mistral": {
      "name": "Mistral AI",
      "website": "https://mistral.ai",
      "api_endpoint": "https://api.mistral.ai",
      "last_updated": "2026-02-11T23:38:28.820599",
      "model_count": 10
    },
    "cohere": {
      "name": "Cohere",
      "website": "https://cohere.com",
      "api_endpoint": "https://api.cohere.ai",
      "last_updated": "2026-02-11T23:38:28.832747",
      "model_count": 11
    },
    "xai": {
      "name": "Xai",
      "website": "",
      "api_endpoint": "",
      "last_updated": "2026-02-11T23:38:28.820456",
      "model_count": 6
    },
    "meta": {
      "name": "Meta",
      "website": "https://meta.com",
      "api_endpoint": "https://api.meta.com",
      "last_updated": "2025-07-17T16:57:28.119320",
      "model_count": 2
    },
    "huggingface": {
      "name": "HuggingFace",
      "website": "https://huggingface.co",
      "api_endpoint": "https://api-inference.huggingface.co",
      "last_updated": "2026-02-11T23:38:28.936653",
      "model_count": 11
    }
  },
  "models": [
    {
      "id": "deepseek-v3",
      "name": "DeepSeek V3",
      "provider": "deepseek",
      "description": "Latest flagship model with 671B parameters and enhanced reasoning",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-12-26",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "coding",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Complex reasoning tasks",
        "Advanced coding projects",
        "Research assistance",
        "Multi-step problem solving",
        "Technical writing",
        "Code review and analysis"
      ],
      "training_cutoff": "2024-09",
      "last_updated": "2026-02-11T23:38:28.668748",
      "unique_id": "deepseek/deepseek-v3"
    },
    {
      "id": "deepseek-v2.5",
      "name": "DeepSeek V2.5",
      "provider": "deepseek",
      "description": "Enhanced version with improved coding and reasoning capabilities",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-09-05",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "coding",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "General programming",
        "Code generation",
        "Algorithm design",
        "Technical documentation",
        "System architecture"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.668764",
      "unique_id": "deepseek/deepseek-v2.5"
    },
    {
      "id": "deepseek-coder-v2",
      "name": "DeepSeek Coder V2",
      "provider": "deepseek",
      "description": "Specialized coding model with 236B parameters",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-06-17",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "function-calling",
        "code-completion"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Software development",
        "Code completion",
        "Bug fixing",
        "Code refactoring",
        "API development",
        "Test generation"
      ],
      "training_cutoff": "2024-04",
      "last_updated": "2026-02-11T23:38:28.668768",
      "unique_id": "deepseek/deepseek-coder-v2"
    },
    {
      "id": "deepseek-chat",
      "name": "DeepSeek Chat",
      "provider": "deepseek",
      "description": "General-purpose conversational AI model",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 4096,
      "release_date": "2024-01-01",
      "status": "ga",
      "features": [
        "chat",
        "reasoning"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "General conversations",
        "Q&A systems",
        "Content creation",
        "Simple reasoning",
        "Educational assistance"
      ],
      "training_cutoff": "2023-10",
      "last_updated": "2026-02-11T23:38:28.668772",
      "unique_id": "deepseek/deepseek-chat"
    },
    {
      "id": "deepseek-coder",
      "name": "DeepSeek Coder",
      "provider": "deepseek",
      "description": "Code-specialized model for programming tasks",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 16384,
      "max_output": 4096,
      "release_date": "2024-01-01",
      "status": "ga",
      "features": [
        "coding",
        "code-completion",
        "debug"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Code completion",
        "Simple programming tasks",
        "Script generation",
        "Code explanation"
      ],
      "training_cutoff": "2023-10",
      "last_updated": "2026-02-11T23:38:28.668775",
      "unique_id": "deepseek/deepseek-coder"
    },
    {
      "id": "deepseek-math",
      "name": "DeepSeek Math",
      "provider": "deepseek",
      "description": "Mathematics and reasoning specialized model",
      "pricing": {
        "input": 0.14,
        "output": 0.28,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 4096,
      "release_date": "2024-02-01",
      "status": "ga",
      "features": [
        "reasoning",
        "math",
        "problem-solving"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Mathematical problem solving",
        "Equation solving",
        "Proof generation",
        "Scientific calculations",
        "Statistical analysis"
      ],
      "training_cutoff": "2023-12",
      "last_updated": "2026-02-11T23:38:28.668778",
      "unique_id": "deepseek/deepseek-math"
    },
    {
      "id": "claude-3-5-sonnet-20241022",
      "name": "Claude 3.5 Sonnet",
      "provider": "anthropic",
      "description": "Most intelligent model, combining top-tier performance with improved speed",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 8192,
      "release_date": "2024-10-22",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "tool-use",
        "json-mode",
        "computer-use"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Complex reasoning",
        "Creative writing",
        "Code generation",
        "Computer automation",
        "Advanced analysis",
        "Image understanding"
      ],
      "training_cutoff": "2024-04",
      "last_updated": "2026-02-11T23:38:28.669289",
      "unique_id": "anthropic/claude-3-5-sonnet-20241022"
    },
    {
      "id": "claude-3-5-haiku-20241022",
      "name": "Claude 3.5 Haiku",
      "provider": "anthropic",
      "description": "Fast and affordable model for everyday tasks",
      "pricing": {
        "input": 1.0,
        "output": 5.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 8192,
      "release_date": "2024-11-04",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "tool-use",
        "json-mode"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Customer support",
        "Content moderation",
        "Quick data extraction",
        "Simple automation",
        "Basic image analysis"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.669300",
      "unique_id": "anthropic/claude-3-5-haiku-20241022"
    },
    {
      "id": "claude-3-opus-20240229",
      "name": "Claude 3 Opus",
      "provider": "anthropic",
      "description": "Powerful model for highly complex tasks",
      "pricing": {
        "input": 15.0,
        "output": 75.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "2024-02-29",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "tool-use"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Research analysis",
        "Complex problem solving",
        "Advanced mathematics",
        "Expert-level tasks"
      ],
      "training_cutoff": "2023-08",
      "last_updated": "2026-02-11T23:38:28.669305",
      "unique_id": "anthropic/claude-3-opus-20240229"
    },
    {
      "id": "claude-3-sonnet-20240229",
      "name": "Claude 3 Sonnet",
      "provider": "anthropic",
      "description": "Balanced performance and speed",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "2024-02-29",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "tool-use"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "General assistance",
        "Content creation",
        "Data analysis",
        "Code review"
      ],
      "training_cutoff": "2023-08",
      "last_updated": "2026-02-11T23:38:28.669309",
      "unique_id": "anthropic/claude-3-sonnet-20240229"
    },
    {
      "id": "claude-3-haiku-20240307",
      "name": "Claude 3 Haiku",
      "provider": "anthropic",
      "description": "Fast, compact model for lightweight tasks",
      "pricing": {
        "input": 0.25,
        "output": 1.25,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "2024-03-07",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "tool-use"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Quick responses",
        "Simple queries",
        "Basic tasks",
        "High-volume processing"
      ],
      "training_cutoff": "2023-08",
      "last_updated": "2026-02-11T23:38:28.669312",
      "unique_id": "anthropic/claude-3-haiku-20240307"
    },
    {
      "id": "claude-2.1",
      "name": "Claude 2.1",
      "provider": "anthropic",
      "description": "Previous generation model",
      "pricing": {
        "input": 8.0,
        "output": 24.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 4096,
      "release_date": "2023-11-21",
      "status": "deprecated",
      "features": [
        "chat"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "2023-01",
      "last_updated": "2026-02-11T23:38:28.669318",
      "unique_id": "anthropic/claude-2.1"
    },
    {
      "id": "claude-2.0",
      "name": "Claude 2.0",
      "provider": "anthropic",
      "description": "Previous generation model",
      "pricing": {
        "input": 8.0,
        "output": 24.0,
        "unit": "1M tokens"
      },
      "context_window": 100000,
      "max_output": 4096,
      "release_date": "2023-07-11",
      "status": "deprecated",
      "features": [
        "chat"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "2023-01",
      "last_updated": "2026-02-11T23:38:28.669321",
      "unique_id": "anthropic/claude-2.0"
    },
    {
      "id": "claude-instant-1.2",
      "name": "Claude Instant 1.2",
      "provider": "anthropic",
      "description": "Fast, affordable model (legacy)",
      "pricing": {
        "input": 0.8,
        "output": 2.4,
        "unit": "1M tokens"
      },
      "context_window": 100000,
      "max_output": 4096,
      "release_date": "2023-08-09",
      "status": "deprecated",
      "features": [
        "chat"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "2023-01",
      "last_updated": "2026-02-11T23:38:28.669324",
      "unique_id": "anthropic/claude-instant-1.2"
    },
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "openai",
      "description": "Most capable multimodal model with vision and advanced reasoning",
      "pricing": {
        "input": 2.5,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 16384,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327599",
      "unique_id": "openai/gpt-4o"
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT-4o mini",
      "provider": "openai",
      "description": "Affordable multimodal model with vision capabilities",
      "pricing": {
        "input": 0.15,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 16384,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode",
        "fast",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327610",
      "unique_id": "openai/gpt-4o-mini"
    },
    {
      "id": "o1",
      "name": "o1",
      "provider": "openai",
      "description": "Advanced reasoning model for complex problem-solving",
      "pricing": {
        "input": 15.0,
        "output": 60.0,
        "unit": "1M tokens"
      },
      "context_window": 200000,
      "max_output": 100000,
      "release_date": "",
      "status": "ga",
      "features": [
        "reasoning",
        "complex-tasks",
        "thinking",
        "math",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327614",
      "unique_id": "openai/o1"
    },
    {
      "id": "o1-mini",
      "name": "o1-mini",
      "provider": "openai",
      "description": "Fast reasoning model optimized for coding and STEM",
      "pricing": {
        "input": 3.0,
        "output": 12.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 65536,
      "release_date": "",
      "status": "ga",
      "features": [
        "reasoning",
        "coding",
        "fast",
        "thinking",
        "math",
        "stem"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327617",
      "unique_id": "openai/o1-mini"
    },
    {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo",
      "provider": "openai",
      "description": "Previous generation high-intelligence model with vision",
      "pricing": {
        "input": 10.0,
        "output": 30.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327620",
      "unique_id": "openai/gpt-4-turbo"
    },
    {
      "id": "gpt-3.5-turbo",
      "name": "GPT-3.5 Turbo",
      "provider": "openai",
      "description": "Fast and cost-effective model for simple tasks",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "unit": "1M tokens"
      },
      "context_window": 16385,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "function-calling",
        "fast",
        "cost-effective"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:29.327622",
      "unique_id": "openai/gpt-3.5-turbo"
    },
    {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro",
      "provider": "google",
      "description": "Advanced multimodal model with long context",
      "pricing": {
        "input": 1.25,
        "output": 5.0,
        "unit": "1M tokens"
      },
      "context_window": 2097152,
      "max_output": 8192,
      "release_date": "2024-05-14",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "audio",
        "video",
        "function-calling",
        "json-mode",
        "code-execution"
      ],
      "modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "use_cases": [
        "Document analysis",
        "Long-form content",
        "Code generation",
        "Video understanding",
        "Complex reasoning",
        "Data analysis with code execution"
      ],
      "training_cutoff": "2024-02",
      "last_updated": "2026-02-11T23:38:28.668763",
      "unique_id": "google/gemini-1.5-pro"
    },
    {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "provider": "google",
      "description": "Fast multimodal model optimized for high-volume tasks",
      "pricing": {
        "input": 0.075,
        "output": 0.3,
        "unit": "1M tokens"
      },
      "context_window": 1048576,
      "max_output": 8192,
      "release_date": "2024-05-24",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "audio",
        "video",
        "function-calling",
        "json-mode",
        "code-execution"
      ],
      "modalities": [
        "text",
        "image",
        "audio",
        "video"
      ],
      "use_cases": [
        "High-volume tasks",
        "Quick responses",
        "Content moderation",
        "Real-time applications",
        "Multimodal chatbots"
      ],
      "training_cutoff": "2024-05",
      "last_updated": "2026-02-11T23:38:28.668768",
      "unique_id": "google/gemini-1.5-flash"
    },
    {
      "id": "gemini-1.5-flash-8b",
      "name": "Gemini 1.5 Flash-8B",
      "provider": "google",
      "description": "Smaller, faster variant of Flash optimized for speed",
      "pricing": {
        "input": 0.0375,
        "output": 0.15,
        "unit": "1M tokens"
      },
      "context_window": 1048576,
      "max_output": 8192,
      "release_date": "2024-10-03",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "function-calling",
        "json-mode"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Edge deployment",
        "Low-latency applications",
        "Cost-sensitive tasks",
        "Simple multimodal queries"
      ],
      "training_cutoff": "2024-08",
      "last_updated": "2026-02-11T23:38:28.668772",
      "unique_id": "google/gemini-1.5-flash-8b"
    },
    {
      "id": "gemini-1.0-pro",
      "name": "Gemini 1.0 Pro",
      "provider": "google",
      "description": "First generation Gemini model",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "2023-12-06",
      "status": "ga",
      "features": [
        "chat",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Text generation",
        "Chatbots",
        "Content creation",
        "Basic reasoning"
      ],
      "training_cutoff": "2023-04",
      "last_updated": "2026-02-11T23:38:28.668775",
      "unique_id": "google/gemini-1.0-pro"
    },
    {
      "id": "mistral-large-2411",
      "name": "Mistral Large 2411",
      "provider": "mistral",
      "description": "Latest flagship model with enhanced reasoning and multilingual capabilities",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-11-15",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "function-calling",
        "json-mode",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Complex reasoning tasks",
        "Multilingual applications",
        "Enterprise chatbots",
        "Content generation",
        "Function calling applications",
        "JSON structured outputs"
      ],
      "training_cutoff": "2024-09",
      "last_updated": "2026-02-11T23:38:28.820367",
      "unique_id": "mistral/mistral-large-2411"
    },
    {
      "id": "mistral-large-2407",
      "name": "Mistral Large 2407",
      "provider": "mistral",
      "description": "Previous version of the flagship model",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-07-24",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "function-calling",
        "json-mode",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "General-purpose AI applications",
        "Customer support",
        "Content creation",
        "Research assistance"
      ],
      "training_cutoff": "2024-05",
      "last_updated": "2026-02-11T23:38:28.820377",
      "unique_id": "mistral/mistral-large-2407"
    },
    {
      "id": "mistral-medium",
      "name": "Mistral Medium",
      "provider": "mistral",
      "description": "Balanced model for general-purpose tasks",
      "pricing": {
        "input": 2.7,
        "output": 8.1,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 8192,
      "release_date": "2023-12-11",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Balanced performance tasks",
        "Educational applications",
        "Content moderation",
        "Translation services"
      ],
      "training_cutoff": "2023-10",
      "last_updated": "2026-02-11T23:38:28.820385",
      "unique_id": "mistral/mistral-medium"
    },
    {
      "id": "mistral-small-2409",
      "name": "Mistral Small 2409",
      "provider": "mistral",
      "description": "Cost-effective model for simple tasks",
      "pricing": {
        "input": 0.2,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-09-18",
      "status": "ga",
      "features": [
        "chat",
        "function-calling",
        "json-mode"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Simple Q&A",
        "Basic text generation",
        "Cost-sensitive applications",
        "High-volume processing"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.820388",
      "unique_id": "mistral/mistral-small-2409"
    },
    {
      "id": "mistral-nemo",
      "name": "Mistral Nemo",
      "provider": "mistral",
      "description": "12B parameter model built in partnership with NVIDIA",
      "pricing": {
        "input": 0.15,
        "output": 0.15,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-07-18",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "multilingual",
        "apache-license"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "On-device deployment",
        "Privacy-sensitive applications",
        "Custom fine-tuning",
        "Edge computing"
      ],
      "training_cutoff": "2024-06",
      "last_updated": "2026-02-11T23:38:28.820391",
      "unique_id": "mistral/mistral-nemo"
    },
    {
      "id": "pixtral-large-2411",
      "name": "Pixtral Large 2411",
      "provider": "mistral",
      "description": "Latest multimodal model with vision capabilities",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-11-21",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "reasoning",
        "function-calling",
        "json-mode"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Visual content analysis",
        "Multimodal applications",
        "Document understanding",
        "Image captioning",
        "Visual Q&A"
      ],
      "training_cutoff": "2024-09",
      "last_updated": "2026-02-11T23:38:28.820395",
      "unique_id": "mistral/pixtral-large-2411"
    },
    {
      "id": "pixtral-12b",
      "name": "Pixtral 12B",
      "provider": "mistral",
      "description": "Open-source multimodal model with vision",
      "pricing": {
        "input": 0.15,
        "output": 0.15,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2024-09-11",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "reasoning",
        "apache-license"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Open-source vision projects",
        "Research applications",
        "Custom multimodal solutions"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.820398",
      "unique_id": "mistral/pixtral-12b"
    },
    {
      "id": "codestral-2405",
      "name": "Codestral 2405",
      "provider": "mistral",
      "description": "Code generation model trained on 80+ programming languages",
      "pricing": {
        "input": 0.2,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 8192,
      "release_date": "2024-05-29",
      "status": "ga",
      "features": [
        "coding",
        "code-completion",
        "function-calling"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Code generation",
        "Programming assistance",
        "Code completion",
        "Software development",
        "Algorithm implementation"
      ],
      "training_cutoff": "2024-03",
      "last_updated": "2026-02-11T23:38:28.820402",
      "unique_id": "mistral/codestral-2405"
    },
    {
      "id": "codestral-mamba-2407",
      "name": "Codestral Mamba 2407",
      "provider": "mistral",
      "description": "Code generation model with Mamba architecture for faster inference",
      "pricing": {
        "input": 0.25,
        "output": 0.25,
        "unit": "1M tokens"
      },
      "context_window": 256000,
      "max_output": 8192,
      "release_date": "2024-07-16",
      "status": "ga",
      "features": [
        "coding",
        "code-completion",
        "long-context",
        "fast-inference"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Large codebase analysis",
        "Long code generation",
        "Fast inference coding tasks",
        "Real-time code completion"
      ],
      "training_cutoff": "2024-05",
      "last_updated": "2026-02-11T23:38:28.820528",
      "unique_id": "mistral/codestral-mamba-2407"
    },
    {
      "id": "mistral-7b",
      "name": "Mistral 7B",
      "provider": "mistral",
      "description": "Original open-source model with Apache 2.0 license",
      "pricing": {
        "input": 0.25,
        "output": 0.25,
        "unit": "1M tokens"
      },
      "context_window": 32000,
      "max_output": 8192,
      "release_date": "2023-09-27",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "apache-license",
        "open-source"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Open-source projects",
        "Research and experimentation",
        "Custom fine-tuning",
        "Educational purposes"
      ],
      "training_cutoff": "2023-07",
      "last_updated": "2026-02-11T23:38:28.820534",
      "unique_id": "mistral/mistral-7b",
      "available_providers": [
        "huggingface",
        "mistral"
      ],
      "provider_pricing": {
        "mistral": {
          "input": 0.25,
          "output": 0.25
        },
        "huggingface": {
          "input": 0.25,
          "output": 0.25
        }
      }
    },
    {
      "id": "command-r-plus",
      "name": "Command R+",
      "provider": "cohere",
      "description": "Advanced conversational AI optimized for complex reasoning and RAG",
      "pricing": {
        "input": 3.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-04-04",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "rag",
        "function-calling",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Complex reasoning tasks",
        "RAG applications",
        "Enterprise chatbots",
        "Document analysis",
        "Knowledge base queries",
        "Multi-step workflows"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2026-02-11T23:38:28.832505",
      "unique_id": "cohere/command-r-plus"
    },
    {
      "id": "command-r",
      "name": "Command R",
      "provider": "cohere",
      "description": "Balanced model for retrieval-augmented generation and conversation",
      "pricing": {
        "input": 0.5,
        "output": 1.5,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-03-11",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "rag",
        "function-calling",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Retrieval-augmented generation",
        "Information synthesis",
        "Customer support",
        "Content generation",
        "Question answering"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2026-02-11T23:38:28.832520",
      "unique_id": "cohere/command-r"
    },
    {
      "id": "command",
      "name": "Command",
      "provider": "cohere",
      "description": "General-purpose conversational AI model",
      "pricing": {
        "input": 1.0,
        "output": 2.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 4096,
      "release_date": "2023-06-01",
      "status": "ga",
      "features": [
        "chat",
        "reasoning"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "General conversations",
        "Content creation",
        "Text summarization",
        "Simple Q&A"
      ],
      "training_cutoff": "2023-03",
      "last_updated": "2026-02-11T23:38:28.832525",
      "unique_id": "cohere/command"
    },
    {
      "id": "command-light",
      "name": "Command Light",
      "provider": "cohere",
      "description": "Faster, lighter version for simple tasks",
      "pricing": {
        "input": 0.3,
        "output": 0.6,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 4096,
      "release_date": "2023-06-01",
      "status": "ga",
      "features": [
        "chat",
        "fast-inference"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "High-throughput applications",
        "Real-time chat",
        "Simple text generation",
        "Cost-sensitive deployments"
      ],
      "training_cutoff": "2023-03",
      "last_updated": "2026-02-11T23:38:28.832529",
      "unique_id": "cohere/command-light"
    },
    {
      "id": "command-nightly",
      "name": "Command Nightly",
      "provider": "cohere",
      "description": "Experimental model with latest features",
      "pricing": {
        "input": 15.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-01-01",
      "status": "experimental",
      "features": [
        "chat",
        "reasoning",
        "experimental"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Experimental features testing",
        "Cutting-edge capabilities",
        "Research applications"
      ],
      "training_cutoff": "2024-01",
      "last_updated": "2026-02-11T23:38:28.832533",
      "unique_id": "cohere/command-nightly"
    },
    {
      "id": "embed-english-v3.0",
      "name": "Embed English v3.0",
      "provider": "cohere",
      "description": "State-of-the-art English text embeddings",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "semantic-search",
        "clustering"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Semantic search",
        "Text similarity",
        "Document clustering",
        "Recommendation systems",
        "Content classification"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832536",
      "unique_id": "cohere/embed-english-v3.0"
    },
    {
      "id": "embed-multilingual-v3.0",
      "name": "Embed Multilingual v3.0",
      "provider": "cohere",
      "description": "Multilingual text embeddings supporting 100+ languages",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "multilingual",
        "semantic-search"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Cross-lingual search",
        "Multilingual clustering",
        "Global content analysis",
        "International applications"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832539",
      "unique_id": "cohere/embed-multilingual-v3.0"
    },
    {
      "id": "embed-english-light-v3.0",
      "name": "Embed English Light v3.0",
      "provider": "cohere",
      "description": "Lightweight English embeddings for high-throughput applications",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "fast-inference",
        "lightweight"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "High-volume embeddings",
        "Real-time similarity",
        "Edge deployments"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832542",
      "unique_id": "cohere/embed-english-light-v3.0"
    },
    {
      "id": "embed-multilingual-light-v3.0",
      "name": "Embed Multilingual Light v3.0",
      "provider": "cohere",
      "description": "Lightweight multilingual embeddings",
      "pricing": {
        "input": 0.1,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 512,
      "max_output": 1024,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "embeddings",
        "multilingual",
        "lightweight"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Lightweight multilingual search",
        "Fast cross-lingual matching"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832548",
      "unique_id": "cohere/embed-multilingual-light-v3.0"
    },
    {
      "id": "rerank-english-v3.0",
      "name": "Rerank English v3.0",
      "provider": "cohere",
      "description": "Advanced reranking model for search relevance",
      "pricing": {
        "input": 2.0,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 1,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "reranking",
        "search-optimization",
        "relevance-scoring"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Search result optimization",
        "Relevance scoring",
        "Information retrieval",
        "Query optimization"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832667",
      "unique_id": "cohere/rerank-english-v3.0"
    },
    {
      "id": "rerank-multilingual-v3.0",
      "name": "Rerank Multilingual v3.0",
      "provider": "cohere",
      "description": "Multilingual reranking for global search applications",
      "pricing": {
        "input": 2.0,
        "output": 0.0,
        "unit": "1M tokens"
      },
      "context_window": 4096,
      "max_output": 1,
      "release_date": "2023-11-02",
      "status": "ga",
      "features": [
        "reranking",
        "multilingual",
        "search-optimization"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Global search systems",
        "Multilingual relevance",
        "Cross-language retrieval"
      ],
      "training_cutoff": "2023-09",
      "last_updated": "2026-02-11T23:38:28.832675",
      "unique_id": "cohere/rerank-multilingual-v3.0"
    },
    {
      "id": "grok-2",
      "name": "Grok 2",
      "provider": "xai",
      "description": "xAI flagship model with enhanced reasoning and real-time knowledge",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 131072,
      "max_output": 8192,
      "release_date": "2024-08-13",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "real-time-data",
        "humor"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Real-time news analysis",
        "Social media insights",
        "Current events discussion",
        "Trend analysis",
        "Interactive conversations",
        "Research with live data"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.820359",
      "unique_id": "xai/grok-2"
    },
    {
      "id": "grok-2-vision",
      "name": "Grok 2 Vision",
      "provider": "xai",
      "description": "Grok 2 with advanced vision capabilities for image understanding",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 131072,
      "max_output": 8192,
      "release_date": "2024-08-13",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "reasoning",
        "real-time-data",
        "humor"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Image analysis with context",
        "Visual content creation",
        "Meme generation and analysis",
        "Social media content review",
        "Real-time image understanding"
      ],
      "training_cutoff": "2024-07",
      "last_updated": "2026-02-11T23:38:28.820375",
      "unique_id": "xai/grok-2-vision"
    },
    {
      "id": "grok-1.5-vision",
      "name": "Grok 1.5 Vision",
      "provider": "xai",
      "description": "Enhanced version with vision capabilities and improved reasoning",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-04-12",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "reasoning",
        "real-time-data"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [
        "Document analysis",
        "Chart and graph interpretation",
        "Visual Q&A",
        "Educational content creation"
      ],
      "training_cutoff": "2024-03",
      "last_updated": "2026-02-11T23:38:28.820379",
      "unique_id": "xai/grok-1.5-vision"
    },
    {
      "id": "grok-1.5",
      "name": "Grok 1.5",
      "provider": "xai",
      "description": "Improved version with better coding and math capabilities",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "2024-03-28",
      "status": "ga",
      "features": [
        "chat",
        "reasoning",
        "coding",
        "math"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Coding assistance",
        "Mathematical problem solving",
        "Technical discussions",
        "Educational tutoring"
      ],
      "training_cutoff": "2024-03",
      "last_updated": "2026-02-11T23:38:28.820385",
      "unique_id": "xai/grok-1.5"
    },
    {
      "id": "grok-1",
      "name": "Grok 1",
      "provider": "xai",
      "description": "Original Grok model with witty and rebellious personality",
      "pricing": {
        "input": 2.0,
        "output": 10.0,
        "unit": "1M tokens"
      },
      "context_window": 8192,
      "max_output": 4096,
      "release_date": "2023-11-04",
      "status": "deprecated",
      "features": [
        "chat",
        "humor",
        "real-time-data"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Casual conversations",
        "Entertainment discussions",
        "Humorous content generation",
        "Alternative perspectives"
      ],
      "training_cutoff": "2023-10",
      "last_updated": "2026-02-11T23:38:28.820388",
      "unique_id": "xai/grok-1"
    },
    {
      "id": "grok-beta",
      "name": "Grok Beta",
      "provider": "xai",
      "description": "Early access model with experimental features",
      "pricing": {
        "input": 5.0,
        "output": 15.0,
        "unit": "1M tokens"
      },
      "context_window": 25000,
      "max_output": 4096,
      "release_date": "2023-12-07",
      "status": "beta",
      "features": [
        "chat",
        "reasoning",
        "experimental"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [
        "Experimental features testing",
        "Edge case discussions",
        "Unconventional problem solving"
      ],
      "training_cutoff": "2023-11",
      "last_updated": "2026-02-11T23:38:28.820391",
      "unique_id": "xai/grok-beta"
    },
    {
      "id": "llama-4-scout",
      "name": "Llama 4 Scout",
      "provider": "meta",
      "description": "Fast and efficient Llama 4 model optimized for speed",
      "pricing": {
        "input": 0.8,
        "output": 2.4,
        "unit": "1M tokens"
      },
      "input_price": 0.8,
      "output_price": 2.4,
      "context_window": 128000,
      "max_output": 8192,
      "release_date": "2025-04-15",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "reasoning",
        "fast",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-07-17T16:57:28.119309",
      "notes": "Released April 2025 - Fastest Llama 4 variant",
      "source": "manual_curation",
      "unique_id": "meta/llama-4-scout"
    },
    {
      "id": "llama-4-maverick",
      "name": "Llama 4 Maverick",
      "provider": "meta",
      "description": "Powerful Llama 4 model with advanced reasoning capabilities",
      "pricing": {
        "input": 2.0,
        "output": 6.0,
        "unit": "1M tokens"
      },
      "input_price": 2.0,
      "output_price": 6.0,
      "context_window": 256000,
      "max_output": 16384,
      "release_date": "2025-04-15",
      "status": "ga",
      "features": [
        "chat",
        "coding",
        "reasoning",
        "creative-writing",
        "analysis",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2025-07-17T16:57:28.119312",
      "notes": "Released April 2025 - Most capable Llama 4 variant",
      "source": "manual_curation",
      "unique_id": "meta/llama-4-maverick"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "name": "Meta Llama 3.1 405B Instruct",
      "provider": "huggingface",
      "description": "Meta의 최대 규모 오픈소스 LLM, 405B 파라미터",
      "pricing": {
        "input": 5.0,
        "output": 16.0,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936555",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "name": "Meta Llama 3.1 70B Instruct",
      "provider": "huggingface",
      "description": "고품질 오픈소스 LLM, 70B 파라미터",
      "pricing": {
        "input": 0.9,
        "output": 0.9,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936565",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct"
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "name": "Meta Llama 3.1 8B Instruct",
      "provider": "huggingface",
      "description": "효율적인 오픈소스 LLM, 8B 파라미터",
      "pricing": {
        "input": 0.2,
        "output": 0.2,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936570",
      "unique_id": "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    {
      "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral 8x7B Instruct",
      "provider": "huggingface",
      "description": "Mistral의 MoE 아키텍처 모델",
      "pricing": {
        "input": 0.7,
        "output": 0.7,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "moe"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936576",
      "unique_id": "huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1"
    },
    {
      "id": "google/gemma-2-27b-it",
      "name": "Google Gemma 2 27B IT",
      "provider": "huggingface",
      "description": "Google의 오픈 모델 Gemma 2세대",
      "pricing": {
        "input": 0.8,
        "output": 0.8,
        "unit": "1M tokens"
      },
      "context_window": 8192,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936582",
      "unique_id": "huggingface/google/gemma-2-27b-it"
    },
    {
      "id": "google/gemma-2-9b-it",
      "name": "Google Gemma 2 9B IT",
      "provider": "huggingface",
      "description": "Google의 경량 Gemma 모델",
      "pricing": {
        "input": 0.3,
        "output": 0.3,
        "unit": "1M tokens"
      },
      "context_window": 8192,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936585",
      "unique_id": "huggingface/google/gemma-2-9b-it"
    },
    {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "name": "Qwen 2.5 72B Instruct",
      "provider": "huggingface",
      "description": "Alibaba의 강력한 다국어 모델",
      "pricing": {
        "input": 0.9,
        "output": 0.9,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936589",
      "unique_id": "huggingface/Qwen/Qwen2.5-72B-Instruct"
    },
    {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "name": "Qwen 2.5 7B Instruct",
      "provider": "huggingface",
      "description": "Qwen 경량 모델",
      "pricing": {
        "input": 0.25,
        "output": 0.25,
        "unit": "1M tokens"
      },
      "context_window": 32768,
      "max_output": 8192,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "multilingual",
        "coding"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936591",
      "unique_id": "huggingface/Qwen/Qwen2.5-7B-Instruct"
    },
    {
      "id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
      "name": "Llama 3.2 11B Vision Instruct",
      "provider": "huggingface",
      "description": "Meta의 비전 기능이 있는 Llama 모델",
      "pricing": {
        "input": 0.35,
        "output": 0.35,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "vision",
        "instruct",
        "multimodal"
      ],
      "modalities": [
        "text",
        "image"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936595",
      "unique_id": "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "id": "microsoft/Phi-3-medium-128k-instruct",
      "name": "Phi-3 Medium 128K Instruct",
      "provider": "huggingface",
      "description": "Microsoft의 효율적인 소형 모델",
      "pricing": {
        "input": 0.4,
        "output": 0.4,
        "unit": "1M tokens"
      },
      "context_window": 128000,
      "max_output": 4096,
      "release_date": "",
      "status": "ga",
      "features": [
        "chat",
        "instruct",
        "long-context"
      ],
      "modalities": [
        "text"
      ],
      "use_cases": [],
      "training_cutoff": "",
      "last_updated": "2026-02-11T23:38:28.936598",
      "unique_id": "huggingface/microsoft/Phi-3-medium-128k-instruct"
    }
  ],
  "statistics": {
    "total_models": 63,
    "free_models": 61,
    "paid_models": 2,
    "providers": 9,
    "provider_breakdown": {
      "deepseek": 6,
      "anthropic": 8,
      "openai": 6,
      "google": 4,
      "mistral": 10,
      "cohere": 11,
      "xai": 6,
      "meta": 2,
      "huggingface": 10
    },
    "price_range": {
      "min": 0.04,
      "max": 15.0,
      "average": 2.14
    },
    "features": {
      "chat": 51,
      "reasoning": 24,
      "coding": 13,
      "function-calling": 18,
      "code-completion": 4,
      "debug": 1,
      "math": 4,
      "problem-solving": 1,
      "vision": 16,
      "tool-use": 5,
      "json-mode": 12,
      "computer-use": 1,
      "multimodal": 3,
      "fast": 4,
      "complex-tasks": 1,
      "thinking": 2,
      "stem": 1,
      "cost-effective": 1,
      "audio": 2,
      "video": 2,
      "code-execution": 2,
      "multilingual": 16,
      "apache-license": 3,
      "long-context": 2,
      "fast-inference": 3,
      "open-source": 1,
      "rag": 2,
      "experimental": 2,
      "embeddings": 4,
      "semantic-search": 2,
      "clustering": 1,
      "lightweight": 2,
      "reranking": 2,
      "search-optimization": 2,
      "relevance-scoring": 1,
      "real-time-data": 4,
      "humor": 3,
      "creative-writing": 1,
      "analysis": 1,
      "instruct": 10,
      "moe": 1
    },
    "modalities": {
      "text": 63,
      "image": 16,
      "audio": 2,
      "video": 2
    },
    "status": {
      "ga": 57,
      "deprecated": 4,
      "experimental": 1,
      "beta": 1
    },
    "context_windows": {
      "min": 512,
      "max": 2097152,
      "over_100k": 38,
      "over_1m": 3
    }
  },
  "metadata": {
    "version": "1.0",
    "data_sources": [
      {
        "provider": "deepseek",
        "file": "deepseek.json",
        "last_updated": "2026-02-11T23:38:28.668846"
      },
      {
        "provider": "anthropic",
        "file": "anthropic.json",
        "last_updated": "2026-02-11T23:38:28.669388"
      },
      {
        "provider": "openai",
        "file": "openai.json",
        "last_updated": "2026-02-11T23:38:29.327704"
      },
      {
        "provider": "google",
        "file": "google.json",
        "last_updated": "2026-02-11T23:38:28.668844"
      },
      {
        "provider": "mistral",
        "file": "mistral.json",
        "last_updated": "2026-02-11T23:38:28.820599"
      },
      {
        "provider": "cohere",
        "file": "cohere.json",
        "last_updated": "2026-02-11T23:38:28.832747"
      },
      {
        "provider": "xai",
        "file": "xai.json",
        "last_updated": "2026-02-11T23:38:28.820456"
      },
      {
        "provider": "meta",
        "file": "meta.json",
        "last_updated": "2025-07-17T16:57:28.119320"
      },
      {
        "provider": "huggingface",
        "file": "huggingface.json",
        "last_updated": "2026-02-11T23:38:28.936653"
      }
    ]
  },
  "categories": {
    "vision_models": [
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/gpt-4-turbo",
      "google/gemini-1.5-pro",
      "google/gemini-1.5-flash",
      "google/gemini-1.5-flash-8b",
      "mistral/pixtral-large-2411",
      "mistral/pixtral-12b",
      "xai/grok-2-vision",
      "xai/grok-1.5-vision",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    ],
    "coding_models": [
      "deepseek/deepseek-coder-v2",
      "deepseek/deepseek-coder",
      "mistral/codestral-2405",
      "mistral/codestral-mamba-2407"
    ],
    "reasoning_models": [
      "deepseek/deepseek-v3",
      "deepseek/deepseek-v2.5",
      "deepseek/deepseek-chat",
      "deepseek/deepseek-math",
      "openai/o1",
      "openai/o1-mini",
      "mistral/mistral-large-2411",
      "mistral/mistral-large-2407",
      "mistral/mistral-medium",
      "mistral/mistral-nemo",
      "mistral/pixtral-large-2411",
      "mistral/pixtral-12b",
      "mistral/mistral-7b",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command",
      "cohere/command-nightly",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-1.5-vision",
      "xai/grok-1.5",
      "xai/grok-beta",
      "meta/llama-4-scout",
      "meta/llama-4-maverick"
    ],
    "fast_models": [
      "openai/gpt-4o-mini",
      "openai/o1-mini",
      "google/gemini-1.5-pro",
      "google/gemini-1.5-flash",
      "google/gemini-1.5-flash-8b",
      "google/gemini-1.0-pro",
      "mistral/mistral-small-2409",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct"
    ],
    "large_context": [
      "deepseek/deepseek-v3",
      "deepseek/deepseek-v2.5",
      "deepseek/deepseek-coder-v2",
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "anthropic/claude-2.1",
      "anthropic/claude-2.0",
      "anthropic/claude-instant-1.2",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o1",
      "openai/o1-mini",
      "openai/gpt-4-turbo",
      "google/gemini-1.5-pro",
      "google/gemini-1.5-flash",
      "google/gemini-1.5-flash-8b",
      "mistral/mistral-large-2411",
      "mistral/mistral-large-2407",
      "mistral/mistral-small-2409",
      "mistral/mistral-nemo",
      "mistral/pixtral-large-2411",
      "mistral/pixtral-12b",
      "mistral/codestral-mamba-2407",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command-nightly",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-1.5-vision",
      "xai/grok-1.5",
      "meta/llama-4-scout",
      "meta/llama-4-maverick",
      "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct",
      "huggingface/microsoft/Phi-3-medium-128k-instruct"
    ],
    "multimodal": [
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/gpt-4-turbo",
      "google/gemini-1.5-pro",
      "google/gemini-1.5-flash",
      "google/gemini-1.5-flash-8b",
      "mistral/pixtral-large-2411",
      "mistral/pixtral-12b",
      "xai/grok-2-vision",
      "xai/grok-1.5-vision",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct"
    ],
    "free_models": [
      "deepseek/deepseek-v3",
      "deepseek/deepseek-v2.5",
      "deepseek/deepseek-coder-v2",
      "deepseek/deepseek-chat",
      "deepseek/deepseek-coder",
      "deepseek/deepseek-math",
      "anthropic/claude-3-5-sonnet-20241022",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-opus-20240229",
      "anthropic/claude-3-sonnet-20240229",
      "anthropic/claude-3-haiku-20240307",
      "anthropic/claude-2.1",
      "anthropic/claude-2.0",
      "anthropic/claude-instant-1.2",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o1",
      "openai/o1-mini",
      "openai/gpt-4-turbo",
      "openai/gpt-3.5-turbo",
      "google/gemini-1.5-pro",
      "google/gemini-1.5-flash",
      "google/gemini-1.5-flash-8b",
      "google/gemini-1.0-pro",
      "mistral/mistral-large-2411",
      "mistral/mistral-large-2407",
      "mistral/mistral-medium",
      "mistral/mistral-small-2409",
      "mistral/mistral-nemo",
      "mistral/pixtral-large-2411",
      "mistral/pixtral-12b",
      "mistral/codestral-2405",
      "mistral/codestral-mamba-2407",
      "mistral/mistral-7b",
      "cohere/command-r-plus",
      "cohere/command-r",
      "cohere/command",
      "cohere/command-light",
      "cohere/command-nightly",
      "cohere/embed-english-v3.0",
      "cohere/embed-multilingual-v3.0",
      "cohere/embed-english-light-v3.0",
      "cohere/embed-multilingual-light-v3.0",
      "cohere/rerank-english-v3.0",
      "cohere/rerank-multilingual-v3.0",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-1.5-vision",
      "xai/grok-1.5",
      "xai/grok-1",
      "xai/grok-beta",
      "huggingface/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-70B-Instruct",
      "huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct",
      "huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "huggingface/google/gemma-2-27b-it",
      "huggingface/google/gemma-2-9b-it",
      "huggingface/Qwen/Qwen2.5-72B-Instruct",
      "huggingface/Qwen/Qwen2.5-7B-Instruct",
      "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct",
      "huggingface/microsoft/Phi-3-medium-128k-instruct"
    ],
    "experimental": [
      "cohere/command-nightly",
      "xai/grok-beta"
    ],
    "deprecated": [
      "anthropic/claude-2.1",
      "anthropic/claude-2.0",
      "anthropic/claude-instant-1.2",
      "xai/grok-1"
    ]
  }
}