import json
import os
from datetime import datetime
from pathlib import Path
from abc import ABC, abstractmethod
import requests
from typing import Dict, List, Optional

class BaseCrawler(ABC):
    """ëª¨ë“  í¬ë¡¤ëŸ¬ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, provider_name: str):
        self.provider_name = provider_name
        self.base_dir = Path(__file__).parent.parent.parent
        self.data_path = self.base_dir / f"data/models/{provider_name}.json"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
    @abstractmethod
    def fetch_models(self) -> List[Dict]:
        """ê° ì œê³µì—…ì²´ì—ì„œ ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ"""
        pass
    
    @abstractmethod
    def get_model_details(self, model_id: str) -> Dict:
        """íŠ¹ì • ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ"""
        pass
    
    def normalize_model_data(self, raw_model: Dict) -> Dict:
        """ëª¨ë¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
        return {
            'id': raw_model.get('id', ''),
            'name': raw_model.get('name', ''),
            'provider': self.provider_name,
            'description': raw_model.get('description', ''),
            'pricing': {
                'input': raw_model.get('input_price', 0),
                'output': raw_model.get('output_price', 0),
                'unit': '1M tokens'
            },
            'context_window': raw_model.get('context_window', 0),
            'max_output': raw_model.get('max_output', 0),
            'release_date': raw_model.get('release_date', ''),
            'status': raw_model.get('status', 'ga'),  # ga, beta, preview, deprecated
            'features': raw_model.get('features', []),
            'modalities': raw_model.get('modalities', ['text']),
            'use_cases': raw_model.get('use_cases', []),
            'training_cutoff': raw_model.get('training_cutoff', ''),
            'last_updated': datetime.now().isoformat()
        }
    
    def save_data(self, models: List[Dict]):
        """JSON íŒŒì¼ë¡œ ë°ì´í„° ì €ì¥"""
        self.data_path.parent.mkdir(parents=True, exist_ok=True)
        
        output = {
            'provider': self.provider_name,
            'provider_info': self.get_provider_info(),
            'last_updated': datetime.now().isoformat(),
            'models': models
        }
        
        with open(self.data_path, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
            
    def get_provider_info(self) -> Dict:
        """ì œê³µì—…ì²´ ì •ë³´ ë°˜í™˜"""
        provider_info = {
            'openai': {
                'name': 'OpenAI',
                'website': 'https://openai.com',
                'api_endpoint': 'https://api.openai.com/v1'
            },
            'anthropic': {
                'name': 'Anthropic',
                'website': 'https://anthropic.com',
                'api_endpoint': 'https://api.anthropic.com'
            },
            'google': {
                'name': 'Google AI',
                'website': 'https://ai.google.dev',
                'api_endpoint': 'https://generativelanguage.googleapis.com'
            },
            'openrouter': {
                'name': 'OpenRouter',
                'website': 'https://openrouter.ai',
                'api_endpoint': 'https://openrouter.ai/api/v1'
            },
            'mistral': {
                'name': 'Mistral AI',
                'website': 'https://mistral.ai',
                'api_endpoint': 'https://api.mistral.ai'
            },
            'cohere': {
                'name': 'Cohere',
                'website': 'https://cohere.com',
                'api_endpoint': 'https://api.cohere.ai'
            }
        }
        
        return provider_info.get(self.provider_name, {
            'name': self.provider_name.title(),
            'website': '',
            'api_endpoint': ''
        })
    
    def parse_price(self, price_text: str) -> float:
        """ê°€ê²© í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜"""
        import re
        # "$2.50 / 1M tokens" -> 2.50
        # "2.50" -> 2.50
        if isinstance(price_text, (int, float)):
            return float(price_text)
            
        match = re.search(r'\$?(\d+\.?\d*)', str(price_text))
        return float(match.group(1)) if match else 0.0
    
    def run(self):
        """í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
        try:
            print(f"ğŸ¤– Starting {self.provider_name} crawler...")
            models = self.fetch_models()
            
            # ëª¨ë¸ ë°ì´í„° ì •ê·œí™”
            normalized_models = []
            for model in models:
                try:
                    normalized = self.normalize_model_data(model)
                    normalized_models.append(normalized)
                except Exception as e:
                    print(f"âŒ Error normalizing model {model.get('id', 'unknown')}: {e}")
                    continue
            
            self.save_data(normalized_models)
            print(f"âœ… Saved {len(normalized_models)} {self.provider_name} models")
            
        except Exception as e:
            print(f"âŒ Error in {self.provider_name} crawler: {e}")
            # ë¹ˆ ë°ì´í„°ë¼ë„ ì €ì¥í•˜ì—¬ ì „ì²´ í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì§€ ì•Šë„ë¡ í•¨
            self.save_data([])