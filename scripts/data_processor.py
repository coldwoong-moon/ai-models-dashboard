#!/usr/bin/env python3
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

class DataProcessor:
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.data_dir = self.base_dir / "data/models"
        self.output_file = self.base_dir / "data/consolidated.json"
        self.history_dir = self.base_dir / "data/history"
        
    def consolidate_data(self) -> Dict[str, Any]:
        """Î™®Îì† Ï†úÍ≥µÏóÖÏ≤¥ Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï©"""
        consolidated = {
            'last_updated': datetime.now().isoformat(),
            'providers': {},
            'models': [],
            'statistics': {},
            'metadata': {
                'version': '1.0',
                'data_sources': []
            }
        }
        
        # Í∞Å Ï†úÍ≥µÏóÖÏ≤¥ Îç∞Ïù¥ÌÑ∞ Î°úÎìú (OpenRouter Ï†úÏô∏)
        excluded_providers = ['openrouter']
        for json_file in self.data_dir.glob("*.json"):
            # OpenRouter ÌååÏùº Ïä§ÌÇµ
            if json_file.stem in excluded_providers:
                continue
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    provider_data = json.load(f)
                
                provider_name = provider_data.get('provider', json_file.stem)
                provider_info = provider_data.get('provider_info', {})
                
                # Ï†úÍ≥µÏóÖÏ≤¥ Ï†ïÎ≥¥ Ï†ÄÏû•
                consolidated['providers'][provider_name] = {
                    'name': provider_info.get('name', provider_name),
                    'website': provider_info.get('website', ''),
                    'api_endpoint': provider_info.get('api_endpoint', ''),
                    'last_updated': provider_data.get('last_updated'),
                    'model_count': len(provider_data.get('models', []))
                }
                
                # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ Ï∂îÍ∞Ä
                consolidated['metadata']['data_sources'].append({
                    'provider': provider_name,
                    'file': json_file.name,
                    'last_updated': provider_data.get('last_updated')
                })
                
                # Î™®Îç∏ Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
                for model in provider_data.get('models', []):
                    # provider ÌïÑÎìú ÌôïÏù∏/Ï∂îÍ∞Ä
                    model['provider'] = provider_name
                    
                    # Í≥†Ïú† ID ÏÉùÏÑ± (provider/model_id ÌòïÏãù)
                    if 'via_openrouter' in model and model.get('via_openrouter'):
                        model['unique_id'] = f"openrouter/{model['id']}"
                    else:
                        model['unique_id'] = f"{provider_name}/{model['id']}"
                    
                    # Î¨¥Î£å Î™®Îç∏ (ÏÇ¨Ïö©Îüâ Ï†úÌïú) Ï†úÏô∏
                    # ÏûÖÎ†•/Ï∂úÎ†• Í∞ÄÍ≤©Ïù¥ Î™®Îëê 0Ïù∏ Î™®Îç∏ÏùÄ Ï†úÏô∏
                    pricing = model.get('pricing', {})
                    input_price = pricing.get('input', 0) or model.get('input_price', 0)
                    output_price = pricing.get('output', 0) or model.get('output_price', 0)
                    
                    if input_price == 0 and output_price == 0:
                        continue  # Î¨¥Î£å Î™®Îç∏ Ï†úÏô∏
                    
                    consolidated['models'].append(model)
                    
            except Exception as e:
                print(f"Error loading {json_file}: {e}")
                continue
        
        # Î™®Îç∏ Ï§ëÎ≥µ Ï†úÍ±∞ (Í∞ôÏùÄ Î™®Îç∏Ïù¥ Ïó¨Îü¨ Ï†úÍ≥µÏóÖÏ≤¥ÏóêÏÑú Ï†úÍ≥µÎêòÎäî Í≤ΩÏö∞)
        consolidated['models'] = self.deduplicate_models(consolidated['models'])
        
        # ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        consolidated['statistics'] = self.calculate_statistics(consolidated['models'])
        
        # Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Î∂ÑÎ•ò
        consolidated['categories'] = self.categorize_models(consolidated['models'])

        # Provider ÎπÑÍµê Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        consolidated['provider_comparison'] = self.create_provider_comparison(consolidated['models'])

        # Í∞ÄÍ≤©ÎåÄÎ≥Ñ Î∂ÑÎ•ò
        consolidated['price_tiers'] = self.classify_by_price_tiers(consolidated['models'])

        return consolidated
    
    def deduplicate_models(self, models: List[Dict]) -> List[Dict]:
        """Ï§ëÎ≥µ Î™®Îç∏ Ï†úÍ±∞ Î∞è Îã§Ï§ë Ï†úÍ≥µÏóÖÏ≤¥ Ï∂îÏ†Å"""
        # Î™®Îç∏ Ïù¥Î¶ÑÍ≥º Ï£ºÏöî ÌååÎùºÎØ∏ÌÑ∞Î°ú Í∑∏Î£πÌôî
        model_groups = {}
        
        for model in models:
            # Î™®Îç∏ Ïù¥Î¶ÑÏóêÏÑú Ï†úÍ≥µÏóÖÏ≤¥ ÌîÑÎ¶¨ÌîΩÏä§ Ï†úÍ±∞ÌïòÍ≥† Í∏∞Î≥∏ Ïù¥Î¶Ñ Ï∂îÏ∂ú
            model_name = model.get('name', '').lower()
            model_id = model.get('id', '').split('/')[-1].lower()
            
            # Í∑∏Î£πÌôî ÌÇ§ ÏÉùÏÑ± (Î™®Îç∏ Ïù¥Î¶Ñ Í∏∞Î∞ò)
            # Ïòà: "Llama 3.1 70B", "GPT-4o" Îì±
            group_key = None
            
            # Llama Î™®Îç∏ Í∑∏Î£πÌôî
            if 'llama' in model_name or 'llama' in model_id:
                if '405b' in model_name or '405b' in model_id:
                    group_key = 'llama-3.1-405b'
                elif '70b' in model_name or '70b' in model_id:
                    group_key = 'llama-3.1-70b'
                elif '8b' in model_name or '8b' in model_id:
                    group_key = 'llama-3.1-8b'
            
            # Mistral Î™®Îç∏ Í∑∏Î£πÌôî
            elif 'mistral' in model_name or 'mistral' in model_id:
                if '7b' in model_name or '7b' in model_id:
                    group_key = 'mistral-7b'
                elif 'mixtral' in model_name or 'mixtral' in model_id:
                    group_key = 'mixtral-8x7b'
            
            # Gemma Î™®Îç∏ Í∑∏Î£πÌôî
            elif 'gemma' in model_name or 'gemma' in model_id:
                if '27b' in model_name or '27b' in model_id:
                    group_key = 'gemma-2-27b'
                elif '9b' in model_name or '9b' in model_id:
                    group_key = 'gemma-2-9b'
            
            # Qwen Î™®Îç∏ Í∑∏Î£πÌôî
            elif 'qwen' in model_name or 'qwen' in model_id:
                if '72b' in model_name or '72b' in model_id:
                    group_key = 'qwen-2.5-72b'
                elif '7b' in model_name or '7b' in model_id:
                    group_key = 'qwen-2.5-7b'
            
            # Í∑∏Î£πÏù¥ ÏóÜÏúºÎ©¥ unique_id ÏÇ¨Ïö©
            if not group_key:
                group_key = model['unique_id']
            
            # Í∑∏Î£πÏóê Ï∂îÍ∞Ä
            if group_key not in model_groups:
                model_groups[group_key] = []
            model_groups[group_key].append(model)
        
        # Í∞Å Í∑∏Î£πÏóêÏÑú ÎåÄÌëú Î™®Îç∏ ÏÑ†ÌÉù Î∞è Îã§Ï§ë Ï†úÍ≥µÏóÖÏ≤¥ Ï∂îÏ†Å
        deduped = []
        for group_key, group_models in model_groups.items():
            if len(group_models) == 1:
                # Îã®Ïùº Ï†úÍ≥µÏóÖÏ≤¥
                deduped.append(group_models[0])
            else:
                # Îã§Ï§ë Ï†úÍ≥µÏóÖÏ≤¥ - Í∞ÄÏû• ÏÉÅÏÑ∏Ìïú Ï†ïÎ≥¥Î•º Í∞ÄÏßÑ Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌïòÍ≥†
                # Îã§Î•∏ Ï†úÍ≥µÏóÖÏ≤¥ Ï†ïÎ≥¥Î•º Ï∂îÍ∞Ä
                primary_model = max(group_models, 
                                   key=lambda m: (
                                       m.get('pricing', {}).get('input', 0),
                                       len(m.get('description', '')),
                                       len(m.get('features', []))
                                   ))
                
                # Îã§Î•∏ Ï†úÍ≥µÏóÖÏ≤¥ Ï†ïÎ≥¥ ÏàòÏßë
                available_providers = [m['provider'] for m in group_models]
                primary_model['available_providers'] = list(set(available_providers))
                
                # Ï†úÍ≥µÏóÖÏ≤¥Î≥Ñ Í∞ÄÍ≤© Ï†ïÎ≥¥ Ï†ÄÏû• (Í∞ÄÍ≤©Ïù¥ Îã§Î•º Í≤ΩÏö∞)
                provider_pricing = {}
                for m in group_models:
                    provider = m['provider']
                    pricing = m.get('pricing', {})
                    if pricing.get('input', 0) > 0:
                        provider_pricing[provider] = {
                            'input': pricing.get('input', 0),
                            'output': pricing.get('output', 0)
                        }
                
                if len(provider_pricing) > 1:
                    primary_model['provider_pricing'] = provider_pricing
                
                deduped.append(primary_model)
        
        return deduped
    
    def calculate_statistics(self, models: List[Dict]) -> Dict[str, Any]:
        """Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞"""
        total_models = len(models)
        
        # Î¨¥Î£å/Ïú†Î£å Î™®Îç∏ Î∂ÑÎ•ò
        free_models = len([
            m for m in models 
            if m.get('pricing', {}).get('input', 0) == 0 or 
               m.get('input_price', 0) == 0
        ])
        
        # Ï†úÍ≥µÏóÖÏ≤¥Î≥Ñ ÌÜµÍ≥Ñ
        providers = {}
        for model in models:
            provider = model.get('provider')
            if provider not in providers:
                providers[provider] = 0
            providers[provider] += 1
        
        # Í∞ÄÍ≤© Î≤îÏúÑ Í≥ÑÏÇ∞
        paid_models = [
            m for m in models 
            if (m.get('pricing', {}).get('input', 0) > 0 or 
                m.get('input_price', 0) > 0)
        ]
        
        if paid_models:
            prices = [
                m.get('pricing', {}).get('input', 0) or m.get('input_price', 0) 
                for m in paid_models
            ]
            min_price = min(prices)
            max_price = max(prices)
            avg_price = sum(prices) / len(prices)
        else:
            min_price = max_price = avg_price = 0
        
        # Í∏∞Îä•Î≥Ñ ÌÜµÍ≥Ñ
        features_count = {}
        for model in models:
            for feature in model.get('features', []):
                if feature not in features_count:
                    features_count[feature] = 0
                features_count[feature] += 1
        
        # Î™®Îã¨Î¶¨Ìã∞Î≥Ñ ÌÜµÍ≥Ñ
        modality_count = {}
        for model in models:
            for modality in model.get('modalities', ['text']):
                if modality not in modality_count:
                    modality_count[modality] = 0
                modality_count[modality] += 1
        
        # ÏÉÅÌÉúÎ≥Ñ ÌÜµÍ≥Ñ
        status_count = {}
        for model in models:
            status = model.get('status', 'ga')
            if status not in status_count:
                status_count[status] = 0
            status_count[status] += 1
        
        return {
            'total_models': total_models,
            'free_models': free_models,
            'paid_models': total_models - free_models,
            'providers': len(providers),
            'provider_breakdown': providers,
            'price_range': {
                'min': round(min_price, 2),
                'max': round(max_price, 2),
                'average': round(avg_price, 2)
            },
            'features': features_count,
            'modalities': modality_count,
            'status': status_count,
            'context_windows': {
                'min': min((m.get('context_window', 0) for m in models if m.get('context_window', 0) > 0), default=0),
                'max': max((m.get('context_window', 0) for m in models), default=0),
                'over_100k': len([m for m in models if m.get('context_window', 0) > 100000]),
                'over_1m': len([m for m in models if m.get('context_window', 0) > 1000000])
            }
        }
    
    def categorize_models(self, models: List[Dict]) -> Dict[str, List[str]]:
        """Î™®Îç∏ÏùÑ Ïπ¥ÌÖåÍ≥†Î¶¨Î≥ÑÎ°ú Î∂ÑÎ•ò"""
        categories = {
            'vision_models': [],
            'coding_models': [],
            'reasoning_models': [],
            'fast_models': [],
            'large_context': [],
            'multimodal': [],
            'free_models': [],
            'experimental': [],
            'deprecated': []
        }
        
        for model in models:
            unique_id = model.get('unique_id', '')
            
            # Vision Î™®Îç∏
            if 'vision' in model.get('features', []) or 'image' in model.get('modalities', []):
                categories['vision_models'].append(unique_id)
            
            # ÏΩîÎî© ÌäπÌôî Î™®Îç∏
            if any(keyword in model.get('name', '').lower() or keyword in model.get('id', '').lower() 
                   for keyword in ['code', 'coder', 'coding']):
                categories['coding_models'].append(unique_id)
            
            # Ï∂îÎ°† Î™®Îç∏
            if any(keyword in model.get('name', '').lower() or keyword in model.get('features', [])
                   for keyword in ['reasoning', 'o1-', 'think']):
                categories['reasoning_models'].append(unique_id)
            
            # Îπ†Î•∏ Î™®Îç∏
            if any(keyword in model.get('name', '').lower() 
                   for keyword in ['fast', 'flash', 'mini', 'small', '8b']):
                categories['fast_models'].append(unique_id)
            
            # ÎåÄÏö©Îüâ Ïª®ÌÖçÏä§Ìä∏
            if model.get('context_window', 0) >= 100000:
                categories['large_context'].append(unique_id)
            
            # Î©ÄÌã∞Î™®Îã¨
            if len(model.get('modalities', [])) > 1:
                categories['multimodal'].append(unique_id)
            
            # Î¨¥Î£å Î™®Îç∏
            if (model.get('pricing', {}).get('input', 0) == 0 or 
                model.get('input_price', 0) == 0):
                categories['free_models'].append(unique_id)
            
            # Ïã§ÌóòÏ†Å Î™®Îç∏
            if model.get('status') in ['experimental', 'preview', 'beta']:
                categories['experimental'].append(unique_id)
            
            # ÏßÄÏõê Ï¢ÖÎ£å Î™®Îç∏
            if model.get('status') == 'deprecated':
                categories['deprecated'].append(unique_id)
        
        return categories

    def create_provider_comparison(self, models: List[Dict]) -> Dict[str, Any]:
        """ProviderÎ≥Ñ Î™®Îç∏ ÎπÑÍµê Ï†ïÎ≥¥ ÏÉùÏÑ±"""
        comparison = {
            'by_use_case': {},
            'by_capability': {},
            'pricing_comparison': {}
        }

        # ÏÇ¨Ïö© ÏÇ¨Î°ÄÎ≥Ñ Î™®Îç∏ Í∑∏Î£πÌôî
        use_cases = {
            'general_chat': {
                'keywords': ['chat', 'conversation', 'general'],
                'models': []
            },
            'advanced_reasoning': {
                'keywords': ['reasoning', 'complex', 'advanced', 'opus', 'o1'],
                'models': []
            },
            'fast_affordable': {
                'keywords': ['fast', 'mini', 'flash', 'haiku', 'small'],
                'models': []
            },
            'vision': {
                'keywords': ['vision', 'image', 'multimodal'],
                'models': []
            },
            'coding': {
                'keywords': ['code', 'coder', 'coding', 'programming'],
                'models': []
            },
            'large_context': {
                'keywords': ['long', 'context', 'large'],
                'min_context': 100000,
                'models': []
            }
        }

        for model in models:
            model_info = {
                'id': model.get('id'),
                'name': model.get('name'),
                'provider': model.get('provider'),
                'input_price': model.get('pricing', {}).get('input', 0) or model.get('input_price', 0),
                'output_price': model.get('pricing', {}).get('output', 0) or model.get('output_price', 0),
                'context_window': model.get('context_window', 0),
                'features': model.get('features', []),
                'unique_id': model.get('unique_id', '')
            }

            # Í∞Å ÏÇ¨Ïö© ÏÇ¨Î°ÄÎ≥ÑÎ°ú Î∂ÑÎ•ò
            for use_case, config in use_cases.items():
                should_include = False

                # ÌÇ§ÏõåÎìú Í∏∞Î∞ò Îß§Ïπ≠
                if 'keywords' in config:
                    model_text = ' '.join([
                        model.get('name', '').lower(),
                        model.get('id', '').lower(),
                        ' '.join(model.get('features', []))
                    ])

                    if any(keyword in model_text for keyword in config['keywords']):
                        should_include = True

                # Ïª®ÌÖçÏä§Ìä∏ ÏúàÎèÑÏö∞ Í∏∞Ï§Ä
                if 'min_context' in config:
                    if model.get('context_window', 0) >= config['min_context']:
                        should_include = True

                if should_include:
                    config['models'].append(model_info)

        # ÏÇ¨Ïö© ÏÇ¨Î°ÄÎ≥ÑÎ°ú Ï†ïÎ¶¨ÌïòÍ≥† Í∞ÄÍ≤©Ïàú Ï†ïÎ†¨
        for use_case, config in use_cases.items():
            sorted_models = sorted(config['models'],
                                 key=lambda m: m['input_price'])
            comparison['by_use_case'][use_case] = sorted_models

        # Í∏∞Îä•Î≥Ñ ÎπÑÍµê (vision, coding Îì±)
        capabilities = ['vision', 'coding', 'reasoning', 'fast']
        for cap in capabilities:
            cap_models = []
            for model in models:
                if cap in model.get('features', []) or cap in model.get('name', '').lower():
                    cap_models.append({
                        'id': model.get('id'),
                        'name': model.get('name'),
                        'provider': model.get('provider'),
                        'input_price': model.get('pricing', {}).get('input', 0) or model.get('input_price', 0),
                        'output_price': model.get('pricing', {}).get('output', 0) or model.get('output_price', 0),
                        'unique_id': model.get('unique_id', '')
                    })

            comparison['by_capability'][cap] = sorted(cap_models,
                                                     key=lambda m: m['input_price'])

        # ProviderÎ≥Ñ Í∞ÄÍ≤© ÎπÑÍµê (ÎèôÏùº ÏûëÏóÖÏóê ÎåÄÌïú ÎπÑÏö©)
        # ÏòàÏãú: 100K input + 10K output ÌÜ†ÌÅ∞
        sample_workload = {
            'input_tokens': 100000,
            'output_tokens': 10000
        }

        provider_costs = {}
        for model in models:
            provider = model.get('provider')
            input_price = model.get('pricing', {}).get('input', 0) or model.get('input_price', 0)
            output_price = model.get('pricing', {}).get('output', 0) or model.get('output_price', 0)

            if input_price > 0:
                # 1M tokens Í∏∞Ï§Ä Í∞ÄÍ≤©ÏùÑ Ïã§Ï†ú ÏÇ¨Ïö©ÎüâÏúºÎ°ú Í≥ÑÏÇ∞
                cost = (input_price * sample_workload['input_tokens'] / 1000000 +
                       output_price * sample_workload['output_tokens'] / 1000000)

                if provider not in provider_costs:
                    provider_costs[provider] = []

                provider_costs[provider].append({
                    'model': model.get('name'),
                    'model_id': model.get('id'),
                    'cost_for_sample': round(cost, 4),
                    'input_price': input_price,
                    'output_price': output_price,
                    'unique_id': model.get('unique_id', '')
                })

        # ProviderÎ≥ÑÎ°ú Ï†ïÎ†¨
        for provider in provider_costs:
            provider_costs[provider] = sorted(provider_costs[provider],
                                            key=lambda m: m['cost_for_sample'])

        comparison['pricing_comparison'] = {
            'sample_workload': sample_workload,
            'by_provider': provider_costs
        }

        return comparison

    def classify_by_price_tiers(self, models: List[Dict]) -> Dict[str, List[Dict]]:
        """Í∞ÄÍ≤©ÎåÄÎ≥ÑÎ°ú Î™®Îç∏ Î∂ÑÎ•ò"""
        tiers = {
            'budget': {'max': 1.0, 'models': []},      # < $1/M tokens
            'standard': {'min': 1.0, 'max': 5.0, 'models': []},  # $1-5/M tokens
            'premium': {'min': 5.0, 'max': 15.0, 'models': []},  # $5-15/M tokens
            'enterprise': {'min': 15.0, 'models': []}  # > $15/M tokens
        }

        for model in models:
            input_price = model.get('pricing', {}).get('input', 0) or model.get('input_price', 0)

            if input_price == 0:
                continue

            model_info = {
                'id': model.get('id'),
                'name': model.get('name'),
                'provider': model.get('provider'),
                'input_price': input_price,
                'output_price': model.get('pricing', {}).get('output', 0) or model.get('output_price', 0),
                'context_window': model.get('context_window', 0),
                'features': model.get('features', []),
                'unique_id': model.get('unique_id', '')
            }

            # Í∞ÄÍ≤©ÎåÄ Î∂ÑÎ•ò
            if input_price < 1.0:
                tiers['budget']['models'].append(model_info)
            elif 1.0 <= input_price < 5.0:
                tiers['standard']['models'].append(model_info)
            elif 5.0 <= input_price < 15.0:
                tiers['premium']['models'].append(model_info)
            else:
                tiers['enterprise']['models'].append(model_info)

        # Í∞Å Ìã∞Ïñ¥Î≥ÑÎ°ú Í∞ÄÍ≤©Ïàú Ï†ïÎ†¨
        for tier in tiers.values():
            tier['models'] = sorted(tier['models'],
                                  key=lambda m: m['input_price'])

        return tiers

    def save_history_snapshot(self, data: Dict[str, Any]):
        """ÏùºÎ≥Ñ ÌûàÏä§ÌÜ†Î¶¨ Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû•"""
        today = datetime.now().strftime("%Y-%m-%d")
        history_file = self.history_dir / f"{today}.json"
        
        self.history_dir.mkdir(parents=True, exist_ok=True)
        
        # ÌûàÏä§ÌÜ†Î¶¨Ïö© Í∞ÑÏÜåÌôîÎêú Îç∞Ïù¥ÌÑ∞
        history_data = {
            'date': today,
            'timestamp': datetime.now().isoformat(),
            'statistics': data['statistics'],
            'provider_count': len(data['providers']),
            'model_count': len(data['models']),
            'price_snapshot': [
                {
                    'unique_id': model.get('unique_id'),
                    'id': model['id'],
                    'name': model['name'],
                    'provider': model['provider'],
                    'input_price': model.get('pricing', {}).get('input', 0) or model.get('input_price', 0),
                    'output_price': model.get('pricing', {}).get('output', 0) or model.get('output_price', 0),
                    'context_window': model.get('context_window', 0),
                    'status': model.get('status', 'ga')
                }
                for model in data['models']
            ]
        }
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2, ensure_ascii=False)
    
    def run(self):
        """Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ïã§Ìñâ"""
        print("üìä Starting data consolidation...")
        
        # Îç∞Ïù¥ÌÑ∞ ÌÜµÌï©
        consolidated = self.consolidate_data()
        
        # ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(consolidated, f, indent=2, ensure_ascii=False)
        
        # ÌûàÏä§ÌÜ†Î¶¨ Ïä§ÎÉÖÏÉ∑ Ï†ÄÏû•
        self.save_history_snapshot(consolidated)
        
        # ÏöîÏïΩ Ï∂úÎ†•
        stats = consolidated['statistics']
        print(f"‚úÖ Data consolidation complete!")
        print(f"   - Total models: {stats['total_models']}")
        print(f"   - Providers: {stats['providers']}")
        print(f"   - Free models: {stats['free_models']}")
        print(f"   - Paid models: {stats['paid_models']}")
        print(f"   - Price range: ${stats['price_range']['min']} - ${stats['price_range']['max']}")
        print(f"   - Models with >100K context: {stats['context_windows']['over_100k']}")
        print(f"   - Models with >1M context: {stats['context_windows']['over_1m']}")

if __name__ == "__main__":
    processor = DataProcessor()
    processor.run()