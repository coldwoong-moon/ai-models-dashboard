#!/usr/bin/env python3
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

class DataProcessor:
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.data_dir = self.base_dir / "data/models"
        self.output_file = self.base_dir / "data/consolidated.json"
        self.history_dir = self.base_dir / "data/history"
        
    def consolidate_data(self) -> Dict[str, Any]:
        """ëª¨ë“  ì œê³µì—…ì²´ ë°ì´í„°ë¥¼ í†µí•©"""
        consolidated = {
            'last_updated': datetime.now().isoformat(),
            'providers': {},
            'models': [],
            'statistics': {},
            'metadata': {
                'version': '1.0',
                'data_sources': []
            }
        }
        
        # ê° ì œê³µì—…ì²´ ë°ì´í„° ë¡œë“œ (OpenRouter ì œì™¸)
        excluded_providers = ['openrouter']
        for json_file in self.data_dir.glob("*.json"):
            # OpenRouter íŒŒì¼ ìŠ¤í‚µ
            if json_file.stem in excluded_providers:
                continue
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    provider_data = json.load(f)
                
                provider_name = provider_data.get('provider', json_file.stem)
                provider_info = provider_data.get('provider_info', {})
                
                # ì œê³µì—…ì²´ ì •ë³´ ì €ìž¥
                consolidated['providers'][provider_name] = {
                    'name': provider_info.get('name', provider_name),
                    'website': provider_info.get('website', ''),
                    'api_endpoint': provider_info.get('api_endpoint', ''),
                    'platform_url': provider_info.get('platform_url', ''),
                    'last_updated': provider_data.get('last_updated'),
                    'model_count': len(provider_data.get('models', []))
                }
                
                # ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
                consolidated['metadata']['data_sources'].append({
                    'provider': provider_name,
                    'file': json_file.name,
                    'last_updated': provider_data.get('last_updated')
                })
                
                # ëª¨ë¸ ë°ì´í„° ì¶”ê°€
                for model in provider_data.get('models', []):
                    # provider í•„ë“œ í™•ì¸/ì¶”ê°€
                    model['provider'] = provider_name
                    
                    # ê³ ìœ  ID ìƒì„± (provider/model_id í˜•ì‹)
                    if 'via_openrouter' in model and model.get('via_openrouter'):
                        model['unique_id'] = f"openrouter/{model['id']}"
                    else:
                        model['unique_id'] = f"{provider_name}/{model['id']}"
                    
                    # ë¬´ë£Œ ëª¨ë¸ (ì‚¬ìš©ëŸ‰ ì œí•œ) ì œì™¸
                    # ìž…ë ¥/ì¶œë ¥ ê°€ê²©ì´ ëª¨ë‘ 0ì¸ ëª¨ë¸ì€ ì œì™¸
                    pricing = model.get('pricing', {})
                    input_price = pricing.get('input', 0) or model.get('input_price', 0)
                    output_price = pricing.get('output', 0) or model.get('output_price', 0)
                    
                    if input_price == 0 and output_price == 0:
                        continue  # ë¬´ë£Œ ëª¨ë¸ ì œì™¸
                    
                    consolidated['models'].append(model)
                    
            except Exception as e:
                print(f"Error loading {json_file}: {e}")
                continue
        
        # ëª¨ë¸ ì¤‘ë³µ ì œê±° (ê°™ì€ ëª¨ë¸ì´ ì—¬ëŸ¬ ì œê³µì—…ì²´ì—ì„œ ì œê³µë˜ëŠ” ê²½ìš°)
        consolidated['models'] = self.deduplicate_models(consolidated['models'])
        
        # í†µê³„ ê³„ì‚°
        consolidated['statistics'] = self.calculate_statistics(consolidated['models'])
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        consolidated['categories'] = self.categorize_models(consolidated['models'])
        
        return consolidated
    
    def deduplicate_models(self, models: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ëª¨ë¸ ì œê±° ë° ë‹¤ì¤‘ ì œê³µì—…ì²´ ì¶”ì """
        # ëª¨ë¸ ì´ë¦„ê³¼ ì£¼ìš” íŒŒë¼ë¯¸í„°ë¡œ ê·¸ë£¹í™”
        model_groups = {}
        
        for model in models:
            # ëª¨ë¸ ì´ë¦„ì—ì„œ ì œê³µì—…ì²´ í”„ë¦¬í”½ìŠ¤ ì œê±°í•˜ê³  ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
            model_name = model.get('name', '').lower()
            model_id = model.get('id', '').split('/')[-1].lower()
            
            # ê·¸ë£¹í™” í‚¤ ìƒì„± (ëª¨ë¸ ì´ë¦„ ê¸°ë°˜)
            # ì˜ˆ: "Llama 3.1 70B", "GPT-4o" ë“±
            group_key = None
            
            # Llama ëª¨ë¸ ê·¸ë£¹í™”
            if 'llama' in model_name or 'llama' in model_id:
                if '405b' in model_name or '405b' in model_id:
                    group_key = 'llama-3.1-405b'
                elif '70b' in model_name or '70b' in model_id:
                    group_key = 'llama-3.1-70b'
                elif '8b' in model_name or '8b' in model_id:
                    group_key = 'llama-3.1-8b'
            
            # Mistral ëª¨ë¸ ê·¸ë£¹í™”
            elif 'mistral' in model_name or 'mistral' in model_id:
                if '7b' in model_name or '7b' in model_id:
                    group_key = 'mistral-7b'
                elif 'mixtral' in model_name or 'mixtral' in model_id:
                    group_key = 'mixtral-8x7b'
            
            # Gemma ëª¨ë¸ ê·¸ë£¹í™”
            elif 'gemma' in model_name or 'gemma' in model_id:
                if '27b' in model_name or '27b' in model_id:
                    group_key = 'gemma-2-27b'
                elif '9b' in model_name or '9b' in model_id:
                    group_key = 'gemma-2-9b'
            
            # Qwen ëª¨ë¸ ê·¸ë£¹í™”
            elif 'qwen' in model_name or 'qwen' in model_id:
                if '72b' in model_name or '72b' in model_id:
                    group_key = 'qwen-2.5-72b'
                elif '7b' in model_name or '7b' in model_id:
                    group_key = 'qwen-2.5-7b'
            
            # ê·¸ë£¹ì´ ì—†ìœ¼ë©´ unique_id ì‚¬ìš©
            if not group_key:
                group_key = model['unique_id']
            
            # ê·¸ë£¹ì— ì¶”ê°€
            if group_key not in model_groups:
                model_groups[group_key] = []
            model_groups[group_key].append(model)
        
        # ê° ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ëª¨ë¸ ì„ íƒ ë° ë‹¤ì¤‘ ì œê³µì—…ì²´ ì¶”ì 
        deduped = []
        for group_key, group_models in model_groups.items():
            if len(group_models) == 1:
                # ë‹¨ì¼ ì œê³µì—…ì²´
                deduped.append(group_models[0])
            else:
                # ë‹¤ì¤‘ ì œê³µì—…ì²´ - ê°€ìž¥ ìƒì„¸í•œ ì •ë³´ë¥¼ ê°€ì§„ ëª¨ë¸ì„ ì„ íƒí•˜ê³ 
                # ë‹¤ë¥¸ ì œê³µì—…ì²´ ì •ë³´ë¥¼ ì¶”ê°€
                primary_model = max(group_models, 
                                   key=lambda m: (
                                       m.get('pricing', {}).get('input', 0),
                                       len(m.get('description', '')),
                                       len(m.get('features', []))
                                   ))
                
                # ë‹¤ë¥¸ ì œê³µì—…ì²´ ì •ë³´ ìˆ˜ì§‘
                available_providers = [m['provider'] for m in group_models]
                primary_model['available_providers'] = list(set(available_providers))
                
                # ì œê³µì—…ì²´ë³„ ê°€ê²© ì •ë³´ ì €ìž¥ (ê°€ê²©ì´ ë‹¤ë¥¼ ê²½ìš°)
                provider_pricing = {}
                for m in group_models:
                    provider = m['provider']
                    pricing = m.get('pricing', {})
                    if pricing.get('input', 0) > 0:
                        provider_pricing[provider] = {
                            'input': pricing.get('input', 0),
                            'output': pricing.get('output', 0)
                        }
                
                if len(provider_pricing) > 1:
                    primary_model['provider_pricing'] = provider_pricing
                
                deduped.append(primary_model)
        
        return deduped
    
    def calculate_statistics(self, models: List[Dict]) -> Dict[str, Any]:
        """ë°ì´í„° í†µê³„ ê³„ì‚°"""
        total_models = len(models)
        
        # ë¬´ë£Œ/ìœ ë£Œ ëª¨ë¸ ë¶„ë¥˜
        free_models = len([
            m for m in models 
            if m.get('pricing', {}).get('input', 0) == 0 or 
               m.get('input_price', 0) == 0
        ])
        
        # ì œê³µì—…ì²´ë³„ í†µê³„
        providers = {}
        for model in models:
            provider = model.get('provider')
            if provider not in providers:
                providers[provider] = 0
            providers[provider] += 1
        
        # ê°€ê²© ë²”ìœ„ ê³„ì‚°
        paid_models = [
            m for m in models 
            if (m.get('pricing', {}).get('input', 0) > 0 or 
                m.get('input_price', 0) > 0)
        ]
        
        if paid_models:
            prices = [
                m.get('pricing', {}).get('input', 0) or m.get('input_price', 0) 
                for m in paid_models
            ]
            min_price = min(prices)
            max_price = max(prices)
            avg_price = sum(prices) / len(prices)
        else:
            min_price = max_price = avg_price = 0
        
        # ê¸°ëŠ¥ë³„ í†µê³„
        features_count = {}
        for model in models:
            for feature in model.get('features', []):
                if feature not in features_count:
                    features_count[feature] = 0
                features_count[feature] += 1
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ í†µê³„
        modality_count = {}
        for model in models:
            for modality in model.get('modalities', ['text']):
                if modality not in modality_count:
                    modality_count[modality] = 0
                modality_count[modality] += 1
        
        # ìƒíƒœë³„ í†µê³„
        status_count = {}
        for model in models:
            status = model.get('status', 'ga')
            if status not in status_count:
                status_count[status] = 0
            status_count[status] += 1
        
        return {
            'total_models': total_models,
            'free_models': free_models,
            'paid_models': total_models - free_models,
            'providers': len(providers),
            'provider_breakdown': providers,
            'price_range': {
                'min': round(min_price, 2),
                'max': round(max_price, 2),
                'average': round(avg_price, 2)
            },
            'features': features_count,
            'modalities': modality_count,
            'status': status_count,
            'context_windows': {
                'min': min((m.get('context_window', 0) for m in models if m.get('context_window', 0) > 0), default=0),
                'max': max((m.get('context_window', 0) for m in models), default=0),
                'over_100k': len([m for m in models if m.get('context_window', 0) > 100000]),
                'over_1m': len([m for m in models if m.get('context_window', 0) > 1000000])
            }
        }
    
    def categorize_models(self, models: List[Dict]) -> Dict[str, List[str]]:
        """ëª¨ë¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            'vision_models': [],
            'coding_models': [],
            'reasoning_models': [],
            'fast_models': [],
            'large_context': [],
            'multimodal': [],
            'free_models': [],
            'experimental': [],
            'deprecated': []
        }
        
        for model in models:
            unique_id = model.get('unique_id', '')
            
            # Vision ëª¨ë¸
            if 'vision' in model.get('features', []) or 'image' in model.get('modalities', []):
                categories['vision_models'].append(unique_id)
            
            # ì½”ë”© íŠ¹í™” ëª¨ë¸
            if any(keyword in model.get('name', '').lower() or keyword in model.get('id', '').lower() 
                   for keyword in ['code', 'coder', 'coding']):
                categories['coding_models'].append(unique_id)
            
            # ì¶”ë¡  ëª¨ë¸
            if any(keyword in model.get('name', '').lower() or keyword in model.get('features', [])
                   for keyword in ['reasoning', 'o1-', 'think']):
                categories['reasoning_models'].append(unique_id)
            
            # ë¹ ë¥¸ ëª¨ë¸
            if any(keyword in model.get('name', '').lower() 
                   for keyword in ['fast', 'flash', 'mini', 'small', '8b']):
                categories['fast_models'].append(unique_id)
            
            # ëŒ€ìš©ëŸ‰ ì»¨í…ìŠ¤íŠ¸
            if model.get('context_window', 0) >= 100000:
                categories['large_context'].append(unique_id)
            
            # ë©€í‹°ëª¨ë‹¬
            if len(model.get('modalities', [])) > 1:
                categories['multimodal'].append(unique_id)
            
            # ë¬´ë£Œ ëª¨ë¸
            if (model.get('pricing', {}).get('input', 0) == 0 or 
                model.get('input_price', 0) == 0):
                categories['free_models'].append(unique_id)
            
            # ì‹¤í—˜ì  ëª¨ë¸
            if model.get('status') in ['experimental', 'preview', 'beta']:
                categories['experimental'].append(unique_id)
            
            # ì§€ì› ì¢…ë£Œ ëª¨ë¸
            if model.get('status') == 'deprecated':
                categories['deprecated'].append(unique_id)
        
        return categories
    
    def save_history_snapshot(self, data: Dict[str, Any]):
        """ì¼ë³„ ížˆìŠ¤í† ë¦¬ ìŠ¤ëƒ…ìƒ· ì €ìž¥"""
        today = datetime.now().strftime("%Y-%m-%d")
        history_file = self.history_dir / f"{today}.json"
        
        self.history_dir.mkdir(parents=True, exist_ok=True)
        
        # ížˆìŠ¤í† ë¦¬ìš© ê°„ì†Œí™”ëœ ë°ì´í„°
        history_data = {
            'date': today,
            'timestamp': datetime.now().isoformat(),
            'statistics': data['statistics'],
            'provider_count': len(data['providers']),
            'model_count': len(data['models']),
            'price_snapshot': [
                {
                    'unique_id': model.get('unique_id'),
                    'id': model['id'],
                    'name': model['name'],
                    'provider': model['provider'],
                    'input_price': model.get('pricing', {}).get('input', 0) or model.get('input_price', 0),
                    'output_price': model.get('pricing', {}).get('output', 0) or model.get('output_price', 0),
                    'context_window': model.get('context_window', 0),
                    'status': model.get('status', 'ga')
                }
                for model in data['models']
            ]
        }
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history_data, f, indent=2, ensure_ascii=False)
    
    def run(self):
        """ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰"""
        print("ðŸ“Š Starting data consolidation...")
        
        # ë°ì´í„° í†µí•©
        consolidated = self.consolidate_data()
        
        # í†µí•© ë°ì´í„° ì €ìž¥
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(consolidated, f, indent=2, ensure_ascii=False)
        
        # ížˆìŠ¤í† ë¦¬ ìŠ¤ëƒ…ìƒ· ì €ìž¥
        self.save_history_snapshot(consolidated)
        
        # ìš”ì•½ ì¶œë ¥
        stats = consolidated['statistics']
        print(f"âœ… Data consolidation complete!")
        print(f"   - Total models: {stats['total_models']}")
        print(f"   - Providers: {stats['providers']}")
        print(f"   - Free models: {stats['free_models']}")
        print(f"   - Paid models: {stats['paid_models']}")
        print(f"   - Price range: ${stats['price_range']['min']} - ${stats['price_range']['max']}")
        print(f"   - Models with >100K context: {stats['context_windows']['over_100k']}")
        print(f"   - Models with >1M context: {stats['context_windows']['over_1m']}")

if __name__ == "__main__":
    processor = DataProcessor()
    processor.run()